{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入包和设置全局路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import lxml.etree as etree\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 设置路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "strJobsDir = \"../jobs_notest\"\n",
    "strZipsDir = \"../zips\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过输入的任务文件夹返回任务文件夹中的所有解调器文件夹路径\n",
    "def fn_getDemodDirsOfAJob(strJobDir):\n",
    "    liststrDemodDirs = [os.path.join(strJobDir, strName) for strName in os.listdir(strJobDir) if \"Demod\" in strName]\n",
    "    return liststrDemodDirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读入任务配置文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入任务计划文件\n",
    "\n",
    "首先清空jobs文件夹。\\\n",
    "WorkSch文件中存放了提前计算出的预计接收开始和结束时间。需利用这个接收开始和结束时间截取出有效时间段。\\\n",
    "可能有多个WorkSch文件，根据它的createdTime选择最新的WorkSch文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(strJobsDir):\n",
    "    shutil.rmtree(strJobsDir)\n",
    "os.mkdir(strJobsDir)\n",
    "for strZipFileName in os.listdir(strZipsDir):\n",
    "    pdTimestampNewestCreated = pd.Timestamp(\"1970-1-1\")\n",
    "    strJobDir = os.path.join(strJobsDir, os.path.splitext(strZipFileName)[0])\n",
    "    os.mkdir(strJobDir)\n",
    "    strZipFile = os.path.join(strZipsDir, strZipFileName)\n",
    "    with zipfile.ZipFile(strZipFile) as oZipFile:\n",
    "        for strFile in oZipFile.namelist():\n",
    "            if \"WorkSch_TASK\" in strFile:\n",
    "                strWorkSchFile = os.path.join(strJobDir, \"work_sch.xml\")\n",
    "                with oZipFile.open(strFile) as f:\n",
    "                    oElementTree = etree.parse(f)\n",
    "                    # f 文件对象只能在parse中使用一次\n",
    "                    # 找到文件创建时间\n",
    "                    pdTimestampCreated = pd.Timestamp(\n",
    "                            oElementTree.find(\"./fileHeader/createdTime\").text)\n",
    "                    if pdTimestampCreated > pdTimestampNewestCreated:\n",
    "                    # 提取最新的文件\n",
    "                        pdTimestampNewestCreated = pdTimestampCreated\n",
    "                        oElementTree.write(strWorkSchFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入设备列表文件\n",
    "任务所用的所有设备都在列表文件里。要根据文件中对设备状态文件的属于的设备的描述提取出用于数据接收传输的设备状态文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strZipFileName in os.listdir(strZipsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, os.path.splitext(strZipFileName)[0])\n",
    "    strZipFile = os.path.join(strZipsDir, strZipFileName)\n",
    "    with zipfile.ZipFile(strZipFile) as oZipFile:\n",
    "        for strFile in oZipFile.namelist():\n",
    "            if \"DeviceList\" in strFile:\n",
    "                strDeviceListFile = os.path.join(strJobDir, \"device_list.xml\")\n",
    "                with oZipFile.open(strFile) as f:\n",
    "                    with open(strDeviceListFile, \"wb\") as f1:\n",
    "                        f1.write(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解调器预处理描述\n",
    "\n",
    "1. 根据任务的设备列表文件找到解调器的设备ID\n",
    "2. 利用设备ID找到解调器的设备状态文件和控制文件，并保存\n",
    "3. 从任务的任务计划文件中读出接收的开始和结束时间，利用接收时间段截取出有效时间段内的记录\n",
    "4. 将解调器的状态参数按照信号处理流程划分为数个最小模块\n",
    "5. 针对每个最小模块产生训练样本和测试样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入设备状态文件和控制文件\n",
    "\n",
    "1. 清空原有的设备文件夹。\n",
    "2. 在设备列表文件中找到解调器设备ID\n",
    "3. 将相应设备状态文件载入设备文件夹\n",
    "\n",
    "执行完成后，任务文件夹里多出如下文件：\n",
    "* 任务名/\n",
    "    * 解调器名/\n",
    "        * raw/\n",
    "            * status.csv\n",
    "        * control.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从zip文件中解压缩具有设备的状态文件，存入raw\n",
    "def fn_extractFilesFromAZip(strJobDir, strID, strZipFile):\n",
    "    strZipDemodStatusFile = \"Status_\" + strID\n",
    "    with zipfile.ZipFile(strZipFile) as oZipFile:\n",
    "        for strFile in oZipFile.namelist():\n",
    "            # 迭代找到zip文件里的解调器的状态文件和控制参数文件\n",
    "            if \"Status_\" + strID in strFile:\n",
    "                # 状态文件\n",
    "                with oZipFile.open(strFile) as f:\n",
    "                    with open(os.path.join(strJobDir, strID + \"/raw/status.csv\"), \"wb\") as f1:\n",
    "                        f1.write(f.read())\n",
    "            elif \"Control_\" + strID in strFile:\n",
    "                # 控制文件\n",
    "                with oZipFile.open(strFile) as f:\n",
    "                    with open(os.path.join(strJobDir, strID + \"/control.csv\"), \"wb\") as f1:\n",
    "                        f1.write(f.read())\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    # 删除原有的解调器文件夹\n",
    "    for strName in os.listdir(strJobDir):\n",
    "        if \"Demod\" in strName:\n",
    "            strDemodDir = os.path.join(strJobDir, strName)\n",
    "            shutil.rmtree(strDemodDir)\n",
    "    \n",
    "    strZipFile = os.path.join(strZipsDir, strJob + \".zip\")\n",
    "    strDeviceListFile = os.path.join(strJobDir, \"device_list.xml\")\n",
    "    oElementTree = etree.parse(strDeviceListFile)\n",
    "    listDevElement = oElementTree.findall(\"./content/deviceList/Device\")\n",
    "    for oElement in listDevElement:\n",
    "        strID = oElement.find(\"DevID\").text\n",
    "        if \"Demod\" in strID:\n",
    "            # 新建解调器文件raw文件夹\n",
    "            os.makedirs(os.path.join(strJobDir, strID + \"/raw\"))\n",
    "            fn_extractFilesFromAZip(strJobDir, strID, strZipFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解调器属性选取（更新）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查所有的解调器状态文件发现，以下属性不是所有的解调器都存在：\n",
    "\n",
    "DEMOD_PHASEROTATION，GLOBAL_DEMOD1STATUS，GLOBAL_TEMPSTATUS，DRU_DISKSPACE1，DRU_USEDSPACE1，DRU_FREESPACE1，DRU_USEDPERCENT1\n",
    "\n",
    "对它们进行忽略。\n",
    "\n",
    "目前发现的在数据集中的值只有一种的属性也全部忽略。以后可能会发现它们有多种值。\n",
    "\n",
    "解调器的状态参数按照参数名的前缀来划分大致有3类——DPU（data packet unit），DEMOD、IFU(中频控制单元)，DRU。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的函数完成的功能如下：\n",
    "* 输入查询的状态参数名称，以字符串形式返回数据集中该参数所具有的所有值组成的集合\n",
    "* 输入任务设定的参数名和对应的值，返回其它任务设定参数的值和该值的对应关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询的状态参数所有可能值\n",
    "def fn_getValuesInStr(strFeature):\n",
    "    setCat = set()\n",
    "    for strJob in os.listdir(strJobsDir):\n",
    "        strJobDir = os.path.join(strJobsDir, strJob)\n",
    "        listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "        for strDemodDir in listDemodDirs:\n",
    "            try:\n",
    "                pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "                for r in pdDfValidStatus.loc[:, strFeature]:\n",
    "                    setCat.add(r)\n",
    "            except:\n",
    "                # 如果该文件里没有查询的参数名，输出文件名\n",
    "                print(strDemodDir)\n",
    "    return str(setCat)\n",
    "\n",
    "# 输出参数具有某一个值的解调器文件夹\n",
    "def fn_getDirOfAValue(strFeature, value):\n",
    "    for strJob in os.listdir(strJobsDir):\n",
    "        listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "        for strDemodDir in listDemodDirs:\n",
    "            pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "            if value in list(pdDfValidStatus.loc[:, strFeature]):\n",
    "                return strDemodDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{1, 2}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_getValuesInStr(\"DEMOD_CARRIERLOCK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../jobs\\\\JOB201912276594418\\\\KJ_HDemodQH1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_getDirOfAValue(\"DPU_RSENABLE1\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 截取出有效接收时间范围内的记录\n",
    "\n",
    "1. 首先清空每个解调器文件夹下的valid文件夹\n",
    "2. 然后从work_sch.xml文件中读入数据接收的有效时间段\n",
    "3. 根据有效时间段截取每个解调器的设备状态文件的有效记录，存入valid文件夹\n",
    "执行完成后，任务文件里多出了如下文件：\n",
    "* 任务名/\n",
    "    * 解调器名/\n",
    "        * valid/\n",
    "            * status.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从指定任务文件夹中读取任务所使用的解调器名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从任务文件夹中提取计划的接收任务开始时间和结束时间\n",
    "def fn_getValidPeriod(strJobDir):\n",
    "    strWorkSchFile = os.path.join(strJobDir, \"work_sch.xml\")\n",
    "    oElementTree = etree.parse(strWorkSchFile)\n",
    "    strReceivingStartTime = \"./content/equipmentInfo/receivingStartTime\"\n",
    "    strReceivingEndTime = \"./content/equipmentInfo/receivingEndTime\"\n",
    "    pdTimestampStart = pd.Timestamp(oElementTree.find(strReceivingStartTime).text)\n",
    "    pdTimestampEnd = pd.Timestamp(oElementTree.find(strReceivingEndTime).text)\n",
    "    return pdTimestampStart, pdTimestampEnd\n",
    "\n",
    "# 利用任务的计划接收开始和结束时间截取解调器的有效状态\n",
    "def fn_extractValidRecordsOfRawStatus(pdTimestampStart, pdTimestampEnd, strStatusDir):\n",
    "    strValidStatusDir = os.path.join(strStatusDir, \"valid\")\n",
    "    if os.path.exists(strValidStatusDir):\n",
    "            shutil.rmtree(strValidStatusDir)\n",
    "    os.mkdir(strValidStatusDir)\n",
    "\n",
    "    strRawStatusFile = os.path.join(strStatusDir, \"raw/status.csv\")\n",
    "    pdDfRawStatus = pd.read_csv(strRawStatusFile, index_col=\"RECTIME\")\n",
    "    pdSeriesFilter = pd.Series(data=pdDfRawStatus.index)\n",
    "    pdSeriesFilter = pdSeriesFilter.apply(lambda t: pd.Timestamp(t))\n",
    "    # 在用值为bool的series作为索引之前，要把series转化为list\n",
    "    pdIndexSeries = (pdSeriesFilter >= pdTimestampStart) & (pdSeriesFilter <= pdTimestampEnd)\n",
    "    pdDfFiltered = pdDfRawStatus.loc[pdIndexSeries.values, :]\n",
    "    strValidStatusFile = os.path.join(strValidStatusDir, \"status.csv\")\n",
    "    pdDfFiltered.to_csv(strValidStatusFile, index_label=\"RECTIME\")\n",
    "\n",
    "# 截取\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    tuplepdTimestamps = fn_getValidPeriod(strJobDir)\n",
    "\n",
    "    liststrDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in liststrDemodDirs:\n",
    "        fn_extractValidRecordsOfRawStatus(tuplepdTimestamps[0],tuplepdTimestamps[1], strDemodDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分描述\n",
    "解调译码过程按照信号处理流程包含如下阶段：\n",
    "* 中频控制\n",
    "* 中频输入\n",
    "* 载波同步\n",
    "* 比特同步\n",
    "* 维特比译码（I/Q路）\n",
    "* 帧同步（I/Q路）\n",
    "* 译码和解扰（I/Q路）\n",
    "任务分为I/Q分路和I/Q合路：\n",
    "* 合路：在维特比译码前，将I和Q路进行并串转换，对转换后的串行信号进行维特比译码即后续操作\n",
    "* 分路：分别对I路和Q路进行维特比译码及后续操作\n",
    "\n",
    "故障诊断的思想：\n",
    "\n",
    "对于一条记录来说，如果在信号处理的某一阶段之前各个阶段的状态参数反映的状态正常，但加上这一阶段的状态参数后，反映的状态不正常，则可说明后面加上去的那一阶段的参数不正常。这样一来，定位出了这个故障记录发生故障的具体阶段。\n",
    "\n",
    "按照这一思想，组合解调译码过程的各个阶段成如下部分：\n",
    "1. 中频控制\n",
    "2. 中频控制、中频输入\n",
    "3. 中频控制，中频输入、载波同步\n",
    "4. 中频控制、中频输入、载波同步、比特同步\n",
    "5. I路：中频控制、中频输入、载波同步、比特同步、维特比译码（I路）\n",
    "6. Q路：中频控制、中频输入、载波同步、比特同步、维特比译码（Q路）\n",
    "7. I路：中频控制、中频输入、载波同步、比特同步、维特比译码（I路）、帧同步（I路）\n",
    "8. Q路：中频控制、中频输入、载波同步、比特同步、维特比译码（Q路）、帧同步（Q路）\n",
    "9. I路：中频控制、中频输入、载波同步、比特同步、维特比译码（I路）、帧同步（I路）、译码和解扰（I路）\n",
    "10. Q路：中频控制、中频输入、载波同步、比特同步、维特比译码（Q路）、帧同步（Q路）、译码和解扰（Q路）\n",
    "\n",
    "可以把一条记录的参数分解成以上各个部分，其中部分2的中频控制参数即为部分1的参数，部分3的中频控制和中频输入部分的参数即为部分2的参数，以此类推。比如：一条异常记录的部分1的参数正常，但部分2的参数异常，则可说明该记录的异常出现在中频输入。\n",
    "\n",
    "一条记录可以产生的样本数并不唯一。一条记录对应于1-4部分中的每个部分可以产生一个样本。如果记录所在的任务为I/Q合路，那么就不会有Q路的信号，即没有6、8、10部分的样本，除了1-4部分、只有5、7、9部分的样本；如果记录所在的任务为I/Q分路，那么I路和Q路都有信号，1-10部分都对应了一个样本。\n",
    "\n",
    "如果一条记录是I/Q合路的，那么当其I路的帧同步锁（DPU_FRAMESYNCSTATUS1）锁上时，这条记录对应的1-4、5、7部分的样本为正常样本，反之这条记录就是一条异常记录，并构成一个在帧同步锁前就发生异常的异常样本；如果一条记录是I/Q分路的，那么只要当它的I路和Q路（DPU_FRAMESYNCSTATUS2）中的某一个帧同步锁锁上时，这条记录对应的1-4部分为正常样本，反之，这条记录为异常记录，并构成一个在帧同步锁前就发生异常的异常样本，更进一步，对于I路和Q路的中锁上的那一路而言，该路对应的样本在加上比特同步后的各个阶段的参数后依然是正常样本，对于I路和Q路中的没锁上的那一路而言，该路加上比特同步后的各个阶段的样本为异常样本。\n",
    "\n",
    "对每一部分都构造一个模型，并且用该部分的80%的正常样本去训练模型，用模型对剩下的20%的正常样本计算分数，找到正常样本所具有的最高分数，以该分数为阈值。在检测时，将异常样本的待检测部分的参数输入相应模型，如果模型输出的分数高于阈值，则证明该样本的该部分相对于上一部分增加的解调译码阶段发生异常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建parts文件夹，存放各部分的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strPartsDir = os.path.join(strDemodDir, \"parts\")\n",
    "        if os.path.exists(strPartsDir):\n",
    "            shutil.rmtree(strPartsDir)\n",
    "        os.mkdir(strPartsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 帧同步锁前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以帧同步锁为界限，把解调器的解调译码阶段分为两部分——帧同步锁前、帧同步锁后。\n",
    "\n",
    "建立空的sync文件夹，存放帧同步锁前的数据集\n",
    "\n",
    "执行后，文件结构如下：\n",
    "* 任务名/\n",
    "    * 解调器名/\n",
    "        * parts/\n",
    "            * sync/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strSyncDir = os.path.join(strDemodDir, \"parts/sync\")\n",
    "        if os.path.exists(strSyncDir):\n",
    "            shutil.rmtree(strSyncDir)\n",
    "        os.mkdir(strSyncDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中频控制\n",
    "可能的属性有： IFU_BWSELECTION（预设的带宽）、IFU_BWSELECTIONSTATUS（实际选择的带宽）、IFU_AGCCONSTANT（预设的agc时间常数）、IFU_AGCCONSTANTSTATUS（实际agc时间常数），IFU_FANSTATUS（风扇开关状态）、IFU_GAINMODESTATUS（增益控制）、IFU_GAIN1STATUS（增益状态）、IFU_GAIN2STATUS、IFU_GAIN3STATUS、IFU_INPUPORTTEMP（入口处温度）、IFU_OUTPUTPORTTEMP（出口处温度）、IFU_OUTPUTLEVELSET（预设输出电平）、IFU_INPUTLEVEL（输入电平）、IFU_OUTPUTLEVEL（输出电平）\n",
    "以下参数不是每个解调器都有：\n",
    "* 实际选择的带宽\n",
    "* 实际agc时间常数\n",
    "* 风扇开关\n",
    "* 增益控制\n",
    "* 增益状态\n",
    "\n",
    "综上所述，选用以下参数作为中频控制特征参数：\n",
    "* IFU_OUTPUTLEVELSET\n",
    "* IFU_INPUTLEVEL\n",
    "* IFU_OUTPUTLEVEL\n",
    "* IFU_INPUPORTTEMP\n",
    "* IFU_OUTPUTPORTTEMP\n",
    "\n",
    "1. 在sync下建立空的ifu文件夹\n",
    "2. 将输入对应的状态参数存入ifu\n",
    "3. 生成输入部分的样本，结果存入ifu/samples\n",
    "4. 对训练样本进行正则化，结果存入ifu/samples/normal/train/preprocessed\n",
    "\n",
    "正则化可将所有训练样本的属性值正则进入0-1之间。只能对训练集进行正则化，在测试的时候，应先用对训练集拟合好的正则化器正则化\n",
    "\n",
    "测试集的样本。\n",
    "执行完成后，具有如下目录结构：\n",
    "* 任务名/\n",
    "    * 解调器名/\n",
    "        * parts/\n",
    "            * sync/\n",
    "                * ifu/\n",
    "                    * samples/\n",
    "                        * normal/\n",
    "                            * train/\n",
    "                                * status.csv\n",
    "                                * preprocessed/\n",
    "                                    * status.csv\n",
    "                            * test/\n",
    "                                * status.csv\n",
    "                        * abnormal/\n",
    "                            * status.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "建立空的ifu文件夹，并将valid中的属于中频控制部分的状态参数存入status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存中频控制部分的特征参数名存入链表\n",
    "listNewFeatures = [\"IFU_OUTPUTLEVELSET\", \"IFU_INPUTLEVEL\", \"IFU_OUTPUTLEVEL\", \"IFU_INPUPORTTEMP\", \\\n",
    "                  \"IFU_OUTPUTPORTTEMP\"]\n",
    "listTotalFeatures = listNewFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空文件夹及载入数据\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    liststrDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in liststrDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/ifu\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "    \n",
    "        # 读入有效解调器设备状态参数\n",
    "        strValidStatusFile = os.path.join(strDemodDir, \"valid/status.csv\")\n",
    "        pdDfValidStatus = pd.read_csv(strValidStatusFile, index_col=\"RECTIME\")\n",
    "        pdDfSectionStatus = pdDfValidStatus[listNewFeatures]\n",
    "        strSectionStatusFile = os.path.join(strSectionDir, \"status.csv\")\n",
    "        pdDfSectionStatus.to_csv(strSectionStatusFile, index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成样本\n",
    "对于每个解调器，首先要从valid文件下的有效接收时间范围内的记录中读取帧同步锁锁上的记录。\n",
    "\n",
    "在从valid文件夹下读取的记录中，选出正常样本。将它们全部用作训练\n",
    "\n",
    "如果DEMOD_FRAMESYNCINPUT是2则任务为分路，如果为1则任务为合路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产生正常样本和异常样本记录indexes的函数。\n",
    "# 先检查DEMOD_FRAMESYNCINPUT的值，如果为合路，则只考虑DPU_FRAMESYNCSTATUS1是否为2；如果为分路，则两者有一个为2即可\n",
    "def fn_getNormalIndexesByFramelock(strDemodDir):\n",
    "    # 针对分路任务具有两个帧同步锁的情况\n",
    "    # 迭代标志数组的每个元素，如果有元素为true，则证明为正常记录\n",
    "    def fn_hasTrue(bnpNArr):\n",
    "        for b in bnpNArr:\n",
    "                if b:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "    pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "    if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "        # 合路\n",
    "        npNArrFilter = (pdDfValidStatus[\"DPU_FRAMESYNCSTATUS1\"] == 2).values\n",
    "        return npNArrFilter, ~npNArrFilter\n",
    "    else:\n",
    "        # 分路\n",
    "        npNArrFilter = (pdDfValidStatus.loc[:, [\"DPU_FRAMESYNCSTATUS1\", \"DPU_FRAMESYNCSTATUS2\"]] == 2).values\n",
    "        npNArrFilter = np.apply_along_axis(fn_hasTrue, 1, npNArrFilter)\n",
    "        return npNArrFilter, ~npNArrFilter\n",
    "\n",
    "# 开始构造样本\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/ifu/samples\")\n",
    "        if os.path.exists(strSamplesDir):\n",
    "            shutil.rmtree(strSamplesDir)\n",
    "        os.mkdir(strSamplesDir)\n",
    "        \n",
    "        # 获取两路通道上帧同步锁有一个锁上的记录索引\n",
    "        npNArrNormalIndexes, npNArrAbnormalIndexes = fn_getNormalIndexesByFramelock(strDemodDir)\n",
    "        \n",
    "        # 读入中频控制部分的状态文件\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/ifu/status.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        # 构造异常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "        pdDfAbnormalTestingSamples = pdDfSectionStatus.loc[npNArrAbnormalIndexes, :]\n",
    "        pdDfAbnormalTestingSamples.to_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), index_label=\"RECTIME\")\n",
    "        \n",
    "        # 新建空的”normal“文件夹\n",
    "        os.makedirs(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "        pdDfNormalTrainingSamples = pdDfSectionStatus.loc[npNArrNormalIndexes, :]\n",
    "        pdDfNormalTrainingSamples.to_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化\n",
    "用正则化器适应训练集，再用正则化器去正则化训练集和测试集。二元参数也可以通过正则化器正则。直接把整个输入部分的训练集正则化即可。将转化的结果存入preprocessed文件夹。该步执行完后，具有的文件夹结构如下：\n",
    "* ifu/\n",
    "    * samples/\n",
    "        * normal/\n",
    "            * train/\n",
    "                * samples.csv\n",
    "                * preprocessed/\n",
    "                    * samples.csv\n",
    "            * test/\n",
    "                * samples.csv\n",
    "                * preprocessed/\n",
    "                    * samples.csv\n",
    "        * abnormal/\n",
    "            * samples.csv\n",
    "            * preprocessed/\n",
    "                * samples.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建正则化器，并读入所有输入部分的训练样本用于正则化器的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读入所有中频控制部分的训练样本\n",
    "listTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfTrainingSamples = pd.read_csv(\\\n",
    "                              os.path.join(strDemodDir, \"parts/sync/ifu/samples/normal/train/samples.csv\"), \\\n",
    "                                          index_col=\"RECTIME\")\n",
    "        listTrainingSamples.append(pdDfTrainingSamples)\n",
    "pdDfTrainingSamples = pd.concat(listTrainingSamples)\n",
    "# 拟合\n",
    "# 正则化器\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(pdDfTrainingSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用拟合训练集的正则化器正则化训练集、正常测试集、异常测试集，存入preprocessed文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 中频控制部分的样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/ifu/samples\")\n",
    "\n",
    "        # 正则化训练集\n",
    "        strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "        # 清空预处理文件夹\n",
    "        if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTrainingSamples.empty:\n",
    "            pdDfNormalTrainingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfNormalTrainingSamples)\n",
    "        # 输出的时候忽略index，因为字符串类型的index在用dataset的时候没法解析\n",
    "        pdDfNormalTrainingSamples.to_csv(os.path.join(strPreprocessedNormalTrainingSamplesDir,\\\n",
    "                                                                  \"samples.csv\"), index=False)\n",
    "        \n",
    "        \n",
    "        # 正则化异常测试集\n",
    "        strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"),\\\n",
    "                                                 index_col=\"RECTIME\")\n",
    "        if not pdDfAbnormalTestingSamples.empty:\n",
    "            pdDfAbnormalTestingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfAbnormalTestingSamples)\n",
    "        pdDfAbnormalTestingSamples.to_csv(os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                          index_label=\"RECTIME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中频输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "中频输入特征参数：DEMOD_IFLEVEL（输入电平），DEMOD_EBNOVALUE（信噪比）。\\\n",
    "本来还想选用DEMOD_EBNOVALUEQCHL，但是这个参数在整个数据集中取值均为零，故忽略。\n",
    "\n",
    "建立空的input文件夹, 并将valid中的属于输入部分的状态参数存入status.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加中频输入部分参数名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把输入部分的属性存一下\n",
    "listNewFeatures = [\"DEMOD_IFLEVEL\", \"DEMOD_EBNOVALUE\"]\n",
    "# 更新总的属性列表。更新之前要检查是否已经更新过\n",
    "if [i for i in listNewFeatures if i in listTotalFeatures]:\n",
    "    pass\n",
    "else:\n",
    "    listTotalFeatures.extend(listNewFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    liststrDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in liststrDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/input\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "    \n",
    "        # 读入有效解调器设备状态参数\n",
    "        strValidStatusFile = os.path.join(strDemodDir, \"valid/status.csv\")\n",
    "        pdDfValidStatus = pd.read_csv(strValidStatusFile, index_col=\"RECTIME\")\n",
    "        pdDfSectionStatus = pdDfValidStatus[listNewFeatures]\n",
    "        pdDfSectionStatus.to_csv(os.path.join(strSectionDir, \"status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成样本\n",
    "需使用中频控制部分的训练集和测试集的index确定中频输入部分的训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 导入输入部分的数据，只包含输入部分的参数\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/input/status.csv\"),\\\n",
    "                                       index_col=\"RECTIME\")\n",
    "        \n",
    "        # 清空输入部分样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/input/samples\")        \n",
    "        if os.path.exists(strSamplesDir):\n",
    "            shutil.rmtree(strSamplesDir)\n",
    "        os.mkdir(strSamplesDir)\n",
    "        # 设置中频控制部分样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/ifu/samples\")\n",
    "        \n",
    "        # 正常样本\n",
    "        os.makedirs(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "        # 读入中频控制部分正常训练样本的index\n",
    "        pdDfLastNormalTrainingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                             index_col=\"RECTIME\")\n",
    "        # 选取正常训练样本的index\n",
    "        pdDfNormalTrainingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTrainingSamples.index, :]\n",
    "        pdDfNormalTrainingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "        # 异常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "        # 读入中频控制部分异常测试样本的index\n",
    "        pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                     index_col=\"RECTIME\")\n",
    "        pdDfAbnormalTestingSamples = \\\n",
    "        pdDfSectionStatus.loc[pdDfLastAbnormalTestingSamples.index, :]\n",
    "        pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化\n",
    "用正则化器适应训练集，再用正则化器去正则化训练集和测试集。二元参数也可以通过正则化器正则。直接把整个输入部分的训练集正则化即可。将转化的结果存入preprocessed文件夹。该步执行完后，具有的文件夹结构如下：\n",
    "* input/\n",
    "    * samples/\n",
    "        * normal/\n",
    "            * train/\n",
    "                * samples.csv\n",
    "                * preprocessed/\n",
    "                    * samples.csv\n",
    "            * test/\n",
    "                * samples.csv\n",
    "                * preprocessed/\n",
    "                    * samples.csv\n",
    "        * abnormal/\n",
    "            * samples.csv\n",
    "            * preprocessed/\n",
    "                * samples.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建正则化器，并读入所有输入部分的训练样本用于正则化器的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读入所有中频控制部分的训练样本\n",
    "listTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfTrainingSamples = pd.read_csv(\\\n",
    "                              os.path.join(strDemodDir, \"parts/sync/input/samples/normal/train/samples.csv\"), \\\n",
    "                                          index_col=\"RECTIME\")\n",
    "        listTrainingSamples.append(pdDfTrainingSamples)\n",
    "pdDfTrainingSamples = pd.concat(listTrainingSamples)\n",
    "# 拟合\n",
    "# 正则化器\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(pdDfTrainingSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用拟合训练集的正则化器正则化训练集、正常测试集、异常测试集，将处理完成的数据集和中频控制部分相应的预处理后的样本集首尾连接。存入preprocessed文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 输入部分的样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/input/samples\")\n",
    "        # 中频控制部分的样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/ifu/samples\")\n",
    "        \n",
    "        # 正则化正常训练集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTrainingSamples.empty:\n",
    "            pdDfNormalTrainingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfNormalTrainingSamples)\n",
    "            # 因为预处理后的中频控制部分状态没有index，所以为了join，必须把这儿的index去掉\n",
    "            pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "        pdDfLastPreprocessedNormalTrainingSamples = pd.read_csv(\\\n",
    "                                      os.path.join(strLastSamplesDir, \"normal/train/preprocessed/samples.csv\"))\n",
    "        pdDfPreprocessedNormalTrainingSamples = pdDfLastPreprocessedNormalTrainingSamples.join(\\\n",
    "                                      pdDfNormalTrainingSamples)\n",
    "        pdDfPreprocessedNormalTrainingSamples.to_csv(\\\n",
    "                                      os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfAbnormalTestingSamples.empty:\n",
    "            pdDfAbnormalTestingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfAbnormalTestingSamples)\n",
    "        pdDfLastPreprocessedAbnormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"abnormal/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedAbnormalTestingSamples = pdDfLastPreprocessedAbnormalTestingSamples.join(\\\n",
    "                                    pdDfAbnormalTestingSamples)\n",
    "        pdDfPreprocessedAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载波同步\n",
    "载波同步特征参数：DEMOD_CARRIEROFFSET（载波偏移）、DEMOD_CARRIERLOCK（载波锁）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "载入载波同步部分到carrier文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把载波同步部分的属性存一下\n",
    "listNewFeatures = [\"DEMOD_CARRIEROFFSET\", \"DEMOD_CARRIERLOCK\"]\n",
    "# 更新总的属性列表。更新之前要检查是否已经更新过\n",
    "if [i for i in listNewFeatures if i in listTotalFeatures]:\n",
    "    pass\n",
    "else:\n",
    "    listTotalFeatures.extend(listNewFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立空的文件夹carrier，将数据导入\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    liststrDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in liststrDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/carrier\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "    \n",
    "        # 读入有效解调器设备状态参数\n",
    "        strValidStatusFile = os.path.join(strDemodDir, \"valid/status.csv\")\n",
    "        pdDfValidStatus = pd.read_csv(strValidStatusFile, index_col=\"RECTIME\")\n",
    "        pdDfSectionStatus = pdDfValidStatus[listNewFeatures]\n",
    "        strSectionStatusFile = os.path.join(strSectionDir, \"status.csv\")\n",
    "        pdDfSectionStatus.to_csv(strSectionStatusFile, index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更改二元属性值\n",
    "DEMOD_CARRIERLOCK属性为锁上时为2，没锁上为1，在此将锁上改为用1表示：\n",
    "1. 将属性等于2的值改为1\n",
    "2. 将属性等于其它值的域改为0\n",
    "\n",
    "执行完成后文件结构如下：\n",
    "* sync/\n",
    "    * carrier/\n",
    "        * status.csv\n",
    "        * regularized/\n",
    "            * status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/carrier/status.csv\"), index_col=\"RECTIME\")\n",
    "        # 更改属性值\n",
    "        npIndexes = pdDfSectionStatus[\"DEMOD_CARRIERLOCK\"].values\n",
    "        npResult = np.zeros(npIndexes.size)\n",
    "        npResult[npIndexes == 2] = 1\n",
    "        pdDfSectionStatus[\"DEMOD_CARRIERLOCK\"] = npResult\n",
    "        \n",
    "        strRegularizedSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/regularized\")\n",
    "        if os.path.exists(strRegularizedSamplesDir):\n",
    "            shutil.rmtree(strRegularizedSamplesDir)\n",
    "        os.mkdir(strRegularizedSamplesDir)\n",
    "        pdDfSectionStatus.to_csv(os.path.join(strRegularizedSamplesDir, \"status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 导入载波同步部分的数据，只包含载波同步部分的参数。注意应该在regularized文件夹下导入\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/carrier/regularized/status.csv\"),\\\n",
    "                                       index_col=\"RECTIME\")\n",
    "        \n",
    "        # 清空载波同步部分样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/samples\")        \n",
    "        if os.path.exists(strSamplesDir):\n",
    "            shutil.rmtree(strSamplesDir)\n",
    "        os.mkdir(strSamplesDir)\n",
    "        # 设置输入部分样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/input/samples\")\n",
    "        \n",
    "        # 正常样本\n",
    "        os.makedirs(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "        # 读入输入部分正常训练样本的index\n",
    "        pdDfLastNormalTrainingSamples = pd.read_csv(\\\n",
    "                             os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                             index_col=\"RECTIME\")\n",
    "        # 选取正常训练样本的index\n",
    "        pdDfNormalTrainingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTrainingSamples.index, :]\n",
    "        pdDfNormalTrainingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "  \n",
    "        # 异常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "        # 读入输入部分异常测试样本的index\n",
    "        pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                     index_col=\"RECTIME\")\n",
    "        pdDfAbnormalTestingSamples = \\\n",
    "        pdDfSectionStatus.loc[pdDfLastAbnormalTestingSamples.index, :]\n",
    "        pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对载波同步部分的所有属性进行正则化，包括二元属性（二元属性正则化后不变）。存入preprocessed文件夹\n",
    "\n",
    "读入所有载波同步正常训练样本，利用正则化器适应正常训练样本。转化所有样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储需要正则化的参数名\n",
    "listNormFeatures = [\"DEMOD_CARRIEROFFSET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listNormalTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strDemodDir, \\\n",
    "                                            \"parts/sync/carrier/samples/normal/train/samples.csv\"),\\\n",
    "                                            index_col=\"RECTIME\")\n",
    "        listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormFeatures])\n",
    "pdDfNormalTrainingSamples = pd.concat(listNormalTrainingSamples)\n",
    "\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(pdDfNormalTrainingSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用正则化器转化所有样本，和输入部分对应的预处理过的样本组合后存入preprocessed文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 输入部分的样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/samples\")\n",
    "        # 中频控制部分的样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/input/samples\")\n",
    "        \n",
    "        # 正则化正常训练集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTrainingSamples.empty:\n",
    "            pdDfNormalTrainingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfNormalTrainingSamples[listNormFeatures])\n",
    "            # 因为预处理后的中频控制部分状态没有index，所以为了join，必须把这儿的index去掉\n",
    "            pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "        pdDfLastPreprocessedNormalTrainingSamples = pd.read_csv(\\\n",
    "                                      os.path.join(strLastSamplesDir, \"normal/train/preprocessed/samples.csv\"))\n",
    "        pdDfPreprocessedNormalTrainingSamples = pdDfLastPreprocessedNormalTrainingSamples.join(\\\n",
    "                                      pdDfNormalTrainingSamples)\n",
    "        pdDfPreprocessedNormalTrainingSamples.to_csv(\\\n",
    "                                      os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index=False)\n",
    "        \n",
    "\n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfAbnormalTestingSamples.empty:\n",
    "            pdDfAbnormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfAbnormalTestingSamples[listNormFeatures])\n",
    "        pdDfLastPreprocessedAbnormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"abnormal/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedAbnormalTestingSamples = pdDfLastPreprocessedAbnormalTestingSamples.join(\\\n",
    "                                    pdDfAbnormalTestingSamples)\n",
    "        pdDfPreprocessedAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比特同步\n",
    "比特同步的特征参数：DEMOD_BITRATE（比特率）、DEMOD_BITRATEOFFSET（比特偏移）、DEMOD_BITRATEOFFSET（比特偏移Q通道）、DEMOD_BITLOCK（比特锁）、DEMOD_BITLOCKQCHL（比特锁Q通道）、DEMOD_TOTALBITNUMBER（总比特数）、DEMOD_TOTALBITNUMBERQCHL（总比特数Q通道）\n",
    "\n",
    "本来对于比特数这个参数，需要用当前秒的比特数减去上一秒的比特数，来得到当前秒接收的比特数。但是减完之后发现，有一些上报秒被的比特数被减成了零。感觉这个参数存在问题，故舍弃。\n",
    "\n",
    "比特率是一个预设值。比特锁属性0为锁上，1为没锁。所以要把它们regularize一下。总比特数是一个累加值，要注意做差分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "存储比特同步增加的属性，更新总的属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "listNewFeatures = [\"DEMOD_BITRATE\", \"DEMOD_BITRATEOFFSET\", \"DEMOD_BITRATEOFFSETQCHL\",\\\n",
    "                   \"DEMOD_BITLOCK\", \"DEMOD_BITLOCKQCHL\"]\n",
    "# 更新总的属性列表。更新之前要检查是否已经更新过\n",
    "if [i for i in listNewFeatures if i in listTotalFeatures]:\n",
    "    pass\n",
    "else:\n",
    "    listTotalFeatures.extend(listNewFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入比特部分的数据入bit文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strBitDir = os.path.join(strDemodDir, \"parts/sync/bit\")\n",
    "        if os.path.exists(strBitDir):\n",
    "            shutil.rmtree(strBitDir)\n",
    "        os.mkdir(strBitDir)\n",
    "        \n",
    "        strValidStatusFile = os.path.join(strDemodDir, \"valid/status.csv\")\n",
    "        pdDfValidStatus = pd.read_csv(strValidStatusFile, index_col=\"RECTIME\")\n",
    "        pdDfBitStatus = pdDfValidStatus[listNewFeatures]\n",
    "        pdDfBitStatus.to_csv(os.path.join(strBitDir, \"status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更改二元属性的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比特锁属性0为锁上，1为没锁。要把比特锁属性值为0改为1，其它改为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/bit\")        \n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strSectionDir, \"status.csv\"), index_col=\"RECTIME\")\n",
    "        # 更改bitlock和bitlcokqchl的值\n",
    "        npIndexes = pdDfSectionStatus[\"DEMOD_BITLOCK\"].values\n",
    "        npResult = np.zeros(npIndexes.size)\n",
    "        npResult[npIndexes == 0] = 1\n",
    "        pdDfSectionStatus[\"DEMOD_BITLOCK\"] = npResult\n",
    "        npIndexes = pdDfSectionStatus[\"DEMOD_BITLOCKQCHL\"].values\n",
    "        npResult = np.zeros(npIndexes.size)\n",
    "        npResult[npIndexes == 0] = 1\n",
    "        pdDfSectionStatus[\"DEMOD_BITLOCKQCHL\"] = npResult\n",
    "        \n",
    "        strRegularizedStatusDir = os.path.join(strSectionDir, \"regularized\")\n",
    "        if os.path.exists(strRegularizedStatusDir):\n",
    "            shutil.rmtree(strRegularizedStatusDir)\n",
    "        os.mkdir(strRegularizedStatusDir)\n",
    "        pdDfSectionStatus.to_csv(os.path.join(strRegularizedStatusDir, \"status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 导入比特同步部分的数据。注意应该在regularized文件夹下导入\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/bit/regularized/status.csv\"),\\\n",
    "                                       index_col=\"RECTIME\")\n",
    "        \n",
    "        # 清空比特同步部分样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/bit/samples\")        \n",
    "        if os.path.exists(strSamplesDir):\n",
    "            shutil.rmtree(strSamplesDir)\n",
    "        os.mkdir(strSamplesDir)\n",
    "        # 设置载波同步样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/samples\")\n",
    "        \n",
    "        # 正常样本\n",
    "        os.makedirs(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "        # 读入输入部分正常训练样本的index\n",
    "        pdDfLastNormalTrainingSamples = pd.read_csv(\\\n",
    "                             os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                             index_col=\"RECTIME\")\n",
    "        # 选取正常训练样本的index\n",
    "        pdDfNormalTrainingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTrainingSamples.index, :]\n",
    "        pdDfNormalTrainingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "        \n",
    "        # 异常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "        # 读入输入部分异常测试样本的index\n",
    "        pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                     index_col=\"RECTIME\")\n",
    "        pdDfAbnormalTestingSamples = \\\n",
    "        pdDfSectionStatus.loc[pdDfLastAbnormalTestingSamples.index, :]\n",
    "        pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二元变量要单独处理。因为如果训练集里所有的某二元变量的值均为1，那么，当用这个训练集训练过后的scaler去转化其它数据集的时候，其他数据集的1变量会被全部转化为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储需要正则化的参数名\n",
    "listNormFeatures = [\"DEMOD_BITRATE\", \"DEMOD_BITRATEOFFSET\", \"DEMOD_BITRATEOFFSETQCHL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listNormalTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strDemodDir, \\\n",
    "                                            \"parts/sync/bit/samples/normal/train/samples.csv\"),\\\n",
    "                                            index_col=\"RECTIME\")\n",
    "        listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormFeatures])\n",
    "        \n",
    "pdDfNormalTrainingSamples = pd.concat(listNormalTrainingSamples)\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(pdDfNormalTrainingSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 比特同步部分的样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/bit/samples\")\n",
    "        # 载波同步部分的样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/samples\")\n",
    "        \n",
    "        # 正则化正常训练集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTrainingSamples.empty:\n",
    "            pdDfNormalTrainingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfNormalTrainingSamples[listNormFeatures])\n",
    "            # 因为预处理后的训练样本没有index，所以为了join，必须把预处理之前的训练样本所含有的index去掉\n",
    "            pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "        pdDfLastPreprocessedNormalTrainingSamples = pd.read_csv(\\\n",
    "                                      os.path.join(strLastSamplesDir, \"normal/train/preprocessed/samples.csv\"))\n",
    "        pdDfPreprocessedNormalTrainingSamples = pdDfLastPreprocessedNormalTrainingSamples.join(\\\n",
    "                                      pdDfNormalTrainingSamples)\n",
    "        pdDfPreprocessedNormalTrainingSamples.to_csv(\\\n",
    "                                      os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 正则化异常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfAbnormalTestingSamples.empty:\n",
    "            pdDfAbnormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfAbnormalTestingSamples[listNormFeatures])\n",
    "        pdDfLastPreprocessedAbnormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"abnormal/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedAbnormalTestingSamples = pdDfLastPreprocessedAbnormalTestingSamples.join(\\\n",
    "                                    pdDfAbnormalTestingSamples)\n",
    "        pdDfPreprocessedAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 维特比译码\n",
    "如果任务为I/Q合路，那么从维特比译码之后都只使用了I路；如果任务为I/Q分路，那么从维特比译码之后使用了两路。\n",
    "\n",
    "载入数据时，要先检查控制文件中的DEMOD_FRAMESYNCINPUT参数.如果I/Q合路，则在vi文件夹下只用建立I文件夹，表示只使用了I路；反之，新建I和Q文件夹。\n",
    "\n",
    "DEMOD_FRAMESYNCINPUT参数有0、1、2三个值，其中已知1代表合路、2代表分路、不知道0代表什么。\n",
    "\n",
    "合路和分路的处理方式具有以下不同：\n",
    "\n",
    "合路只用了I路，所以可以直接依照比特同步阶段的样本index去生成样本；但分路用了两路，每个分路具有自己的帧同步锁，而在分路之前的样本是否为正样本的判断方式是：只要有一个分路的帧同步锁锁上，所以即使分路之前的样本为正常样本，也不能就此判断其对应的两个分路均为正常样本。\n",
    "\n",
    "由于在分路的情况下，正常样本和异常样本可能存在变动，所以记录在分路之前需要进行的预处理也需要重新进行。在载入数据的时候也需要把比特同步部分的属性载进来。\n",
    "\n",
    "维特比译码部分包含参数：DEMOD_VITERBIINPUT（维特比输入开关）、DEMOD_VITERBI1DECODER、DEMOD_VITERBI2DECODER、DEMOD_VITERBI1TOTALBITNUMBER（总比特数）、DEMOD_VITERBI2TOTALBITNUMBER、DEMOD_VITERBI1ERRORBITNUMBER（误比特数）、DEMOD_VITERBI2ERRORBITNUMBER.\\\n",
    "DEMOD_VITERBIINPUT值为2表示维特比打开，所以需要先正规化。\n",
    "跟比特数有关的变量是累加值，所以应该先减去前一秒的值得到这一秒内的包数。但有以下特殊情况：\n",
    "* 有效接收时间的第一秒的比特数是相对于无效接收时间的最后一秒而言的，所以应该先读入无效的最后一秒的比特数\n",
    "* 如果某一秒的包数比前一秒少，那就不用减了\n",
    "\n",
    "在I/Q合路的情况下，维特比译码的样本可以依照比特同步的样本生成。分路情况下，要对于比特同步中的正常样本检查I路和Q路的帧同步锁，把没锁的样本放到异常样本中去。\n",
    "\n",
    "把算完包数的状态参数文件存入diff文件夹，执行完成后具有如下文件结构：\n",
    "* parts/\n",
    "    * sync/\n",
    "        * vi/\n",
    "            * I/\n",
    "                * regularized/\n",
    "                    * status.csv\n",
    "                * diff/\n",
    "                    * status.csv\n",
    "                * status.csv\n",
    "            * Q/（合路时没有这个文件夹）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据\n",
    "清空vi文件夹和其下的I、Q文件夹。读入维特比部分的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 还没有分路之前全部属性，按照顺序存储在链表中。分路之后的全部属性分为两个链表\n",
    "# 把维特比部分的属性存一下。需要把两个通道分别存储\n",
    "listNewIFeatures = [\"DEMOD_VITERBIINPUT\", \"DEMOD_VITERBI1DECODER\",\\\n",
    "            \"DEMOD_VITERBI1TOTALBITNUMBER\", \"DEMOD_VITERBI1ERRORBITNUMBER\"]\n",
    "listTotalIFeatures = listTotalFeatures + listNewIFeatures\n",
    "listNewQFeatures = [\"DEMOD_VITERBIINPUT\", \"DEMOD_VITERBI2DECODER\",\\\n",
    "            \"DEMOD_VITERBI2TOTALBITNUMBER\", \"DEMOD_VITERBI2ERRORBITNUMBER\"]\n",
    "listTotalQFeatures = listTotalFeatures + listNewQFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 读入控制文件，为了判断合路还是分路\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/vi\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "        \n",
    "        pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路，要包括前面的所有属性，因为在正则化的时候，是所有的分路一起正则化，不论是合路还是分路它们的I路和Q路都是\n",
    "            # 同等的关系\n",
    "            os.mkdir(os.path.join(strSectionDir, \"I\"))\n",
    "            pdDfIStatus = pdDfValidStatus[listTotalIFeatures]\n",
    "            pdDfIStatus.to_csv(os.path.join(strSectionDir, \"I/status.csv\"), index_label=\"RECTIME\")\n",
    "        else:\n",
    "            # 分路。要读I路和Q路两路数据。并且要把包括前面的所有的属性都读进来\n",
    "            os.mkdir(os.path.join(strSectionDir, \"I\"))\n",
    "            pdDfIStatus = pdDfValidStatus[listTotalIFeatures]\n",
    "            pdDfIStatus.to_csv(os.path.join(strSectionDir, \"I/status.csv\"), index_label=\"RECTIME\")\n",
    "            os.mkdir(os.path.join(strSectionDir, \"Q\"))\n",
    "            pdDfQStatus = pdDfValidStatus[listTotalQFeatures]\n",
    "            pdDfQStatus.to_csv(os.path.join(strSectionDir, \"Q/status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更改二元属性的值\n",
    "更改DEMOD_VITERBIINPUT的属性，存入regularied。2为维特比有效，其余为无效。\n",
    "* vi/\n",
    "    * I（Q）/\n",
    "        * status.csv\n",
    "        * regularized/\n",
    "            * status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变所有需要改变值的二元属性，由于目前在分路上没有二元属性，所以它们的二元属性都是公共的\n",
    "# 比特同步及之前的部分的二元属性只有在分路的情况下才用改变，因为只有分路的情况才包含前面的所有属性\n",
    "def fn_regularizeIOrQ(strIOrQ):\n",
    "    strRegularizedStatusDir = os.path.join(strSectionDir, strIOrQ + \"/regularized\")\n",
    "    if os.path.exists(strRegularizedStatusDir):\n",
    "        shutil.rmtree(strRegularizedStatusDir)\n",
    "    os.mkdir(strRegularizedStatusDir)\n",
    "    pdDfStatus = pd.read_csv(os.path.join(strSectionDir, strIOrQ + \"/status.csv\"), index_col=\"RECTIME\")\n",
    "    # DEMOD_CARRIERLOCK\n",
    "    npIndexes = pdDfStatus[\"DEMOD_CARRIERLOCK\"].values\n",
    "    npResult = np.zeros(npIndexes.size)\n",
    "    npResult[npIndexes == 2] = 1\n",
    "    pdDfStatus[\"DEMOD_CARRIERLOCK\"] = npResult\n",
    "    # 更改bitlock和bitlcokqchl的值\n",
    "    npIndexes = pdDfStatus[\"DEMOD_BITLOCK\"].values\n",
    "    npResult = np.zeros(npIndexes.size)\n",
    "    npResult[npIndexes == 0] = 1\n",
    "    pdDfStatus[\"DEMOD_BITLOCK\"] = npResult\n",
    "    npIndexes = pdDfStatus[\"DEMOD_BITLOCKQCHL\"].values\n",
    "    npResult = np.zeros(npIndexes.size)\n",
    "    npResult[npIndexes == 0] = 1\n",
    "    pdDfStatus[\"DEMOD_BITLOCKQCHL\"] = npResult\n",
    "    # DEMOD_VITERBIINPUT\n",
    "    npIndexes = pdDfStatus[\"DEMOD_VITERBIINPUT\"].values\n",
    "    npResult = np.zeros(npIndexes.size)\n",
    "    npResult[npIndexes == 2] = 1\n",
    "    pdDfStatus[\"DEMOD_VITERBIINPUT\"] = npResult\n",
    "    pdDfStatus.to_csv(os.path.join(strRegularizedStatusDir, \"status.csv\"), index_label=\"RECTIME\")\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/vi\")   \n",
    "\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路, 直接规整I路\n",
    "            fn_regularizeIOrQ(\"I\")\n",
    "        else:\n",
    "            # 分路，规整I路和Q路的到目前为止所有的需要规整的二元属性\n",
    "            # I路\n",
    "            fn_regularizeIOrQ(\"I\")\n",
    "            # Q路\n",
    "            fn_regularizeIOrQ(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算每秒的比特数\n",
    "先读入raw文件夹下的状态参数。找到第一个有效上报点的前一个点的参数。如果第一个有效上报点的参数大于前一点的参数则做差，反之直接保留。其余上报点的参数直接为该秒的值与前一秒值之差。计算后把状态de文件存入diff文件夹。如果有的秒数在做完差后的值为零，直接令它的值等于前一秒的比特数\n",
    "* I(Q)/\n",
    "    * status.csv\n",
    "    * diff/\n",
    "        * status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存入比特数的属性名\n",
    "listAggreIFeatures = [\"DEMOD_VITERBI1TOTALBITNUMBER\", \"DEMOD_VITERBI1ERRORBITNUMBER\"]\n",
    "listAggreQFeatures = [\"DEMOD_VITERBI2TOTALBITNUMBER\", \"DEMOD_VITERBI2ERRORBITNUMBER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只在维特比译码阶段出现了累积量\n",
    "def fn_subNumber(nWin):\n",
    "        if nWin.size == 1:\n",
    "            return  nWin[0]\n",
    "        elif nWin[1] < nWin[0]:\n",
    "                return nWin[1]\n",
    "        else:\n",
    "                return nWin[1] - nWin[0]\n",
    "\n",
    "# 把0元素全部改为它的上一个元素的值\n",
    "def fn_fillZeros(nWin):\n",
    "    if nWin.size == 1:\n",
    "        return nWin[0]\n",
    "    elif nWin[1] == 0:\n",
    "        return nWin[0]\n",
    "    else:\n",
    "        return nWin[1]\n",
    "\n",
    "# 对状态函数做差。输入状态的通道文件夹，和需要做差的属性，完成做差，存入diff\n",
    "def fn_subIOrQ(strDir, listAggreFeatures):\n",
    "    # 清空diff\n",
    "    strDiffDir = os.path.join(strDir, \"diff\")\n",
    "    if os.path.exists(strDiffDir):\n",
    "        shutil.rmtree(strDiffDir)\n",
    "    os.mkdir(strDiffDir)\n",
    "    pdDfStatus = pd.read_csv(os.path.join(strDir, \"regularized/status.csv\"), index_col=\"RECTIME\")\n",
    "    # 从第二个有效上报时间点开始，算每个点单独的包数\n",
    "    pdDfStatus[listAggreFeatures] = pdDfStatus[listAggreFeatures].rolling(window=2, min_periods=1).\\\n",
    "    apply(fn_subNumber, raw=True)\n",
    "    # 找到第一个有效时间点之前的时间点的整数坐标\n",
    "    strFirstValidIndex = pdDfStatus.index[0]\n",
    "    i = 0\n",
    "    for strIndex in pdDfRawStatus.index:\n",
    "        if strIndex == strFirstValidIndex:\n",
    "            # 取出第一个有效时间点之前的记录和第一个有效时间点记录\n",
    "            pdSeriesRaw = pdDfRawStatus.loc[pdDfRawStatus.index[i - 1], listAggreFeatures]\n",
    "            pdSeriesToBeCulled = pdDfStatus.loc[strFirstValidIndex, listAggreFeatures]\n",
    "            for j in range(len(pdSeriesToBeCulled)):\n",
    "                # 如果第一个有效点记录的在某域上的值大于等于相应的第一个有效时间点之前的记录的值，则做差\n",
    "                pdSeriesToBeCulled[j] = pdSeriesToBeCulled[j] - pdSeriesRaw[j] \\\n",
    "                    if pdSeriesToBeCulled[j] >= pdSeriesRaw[j] else pdSeriesToBeCulled[j]\n",
    "            pdDfStatus.loc[strFirstValidIndex, listAggreFeatures] = pdSeriesToBeCulled\n",
    "        i += 1\n",
    "    # 填充0值\n",
    "    pdDfStatus[listAggreFeatures] = pdDfStatus[listAggreFeatures].rolling(window=2, min_periods=1).\\\n",
    "    apply(fn_fillZeros, raw=True)\n",
    "    pdDfStatus.to_csv(os.path.join(strDiffDir, \"status.csv\"), index_label=\"RECTIME\")\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 读入原始状态参数\n",
    "        pdDfRawStatus = pd.read_csv(os.path.join(strDemodDir, \"raw/status.csv\"), index_col=\"RECTIME\")\n",
    "        # 读入控制参数文件\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        # 因为需要做差的目前只在维特比译码这儿有，所以可以无论如何先做I路，再做选择性的Q路\n",
    "        # 无论如何先做I路\n",
    "        fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/vi/I\"), listAggreIFeatures)\n",
    "        \n",
    "        # 如果分路则做Q路\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 分路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/vi/I\"), listAggreIFeatures)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/vi/I\"), listAggreIFeatures)\n",
    "            # Q路\n",
    "            fn_subCh(os.path.join(strDemodDir, \"parts/sync/vi/Q\"), listAggreQFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在读入比特同步的相应样本后，需要根据不同的分路，检查不同的帧同步锁。把前一次的正常训练样本和正常测试样本中在该分路上没有锁上的\n",
    "# 记录归为该分路上的异常样本\n",
    "# 为了逻辑简便，即使合路不存在这种需要根据分路的帧同步锁再次判断该分路的样本是否为异常样本的情况，还是对合路情况进行如上操作\n",
    "def fn_genIOrQSamples(strIOrQ):\n",
    "    # 清空I和Q路的样本文件夹\n",
    "    strSamplesDir = os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/samples\")\n",
    "    if os.path.exists(strSamplesDir):\n",
    "        shutil.rmtree(strSamplesDir)\n",
    "    os.mkdir(strSamplesDir)\n",
    "\n",
    "    # 导入维特比部分做差后的数据\n",
    "    pdDfStatus = pd.read_csv(\\\n",
    "             os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/diff/status.csv\"), index_col=\"RECTIME\")\n",
    "\n",
    "\n",
    "    # 新建normal和abnormal样本文件夹\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal\"))\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "\n",
    "    # 存储由正常训练样本和正常测试样本转变为异常样本的index的链表\n",
    "    listNewAbnormalIndexes = []\n",
    "    # 找到正常训练样本和正常测试样本中转变为异常测试样本的index，并存入链表\n",
    "    # I路对应DPU_FRAMESYNCSTATUS1；Q路对应DPU_FRAMESYNCSTATUS2\n",
    "    for strIndex in pdDfLastNormalTrainingSamples.index: \n",
    "        if not pdDfValidStatus.loc[strIndex, \"DPU_FRAMESYNCSTATUS\" + (\"1\" if strIOrQ == \"I\" else \"2\")] == 2:\n",
    "            # 没锁上，把index存入链表\n",
    "            listNewAbnormalIndexes.append(strIndex)\n",
    "\n",
    "    # 利用比特同步的正常训练样本的index除去listNewAbnormalIndexes中索引后的index产生正常训练样本\n",
    "    pdDfNormalTrainingSamples = \\\n",
    "        pdDfStatus.loc[[strIndex for strIndex in pdDfLastNormalTrainingSamples.index \\\n",
    "                             if strIndex not in listNewAbnormalIndexes], :]\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "    pdDfNormalTrainingSamples.to_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"), index_label=\"RECTIME\")\n",
    "\n",
    "    # 异常测试样本\n",
    "    pdDfAbnormalTestingSamples = \\\n",
    "        pdDfStatus.loc[list(pdDfLastAbnormalTestingSamples.index) + listNewAbnormalIndexes, :]\n",
    "    pdDfAbnormalTestingSamples.to_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), index_label=\"RECTIME\")\n",
    "    \n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 读入控制文件，为了判断合路还是分路\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        # 设置比特同步样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/bit/samples\")\n",
    "        # 读入比特同步的正常训练样本\n",
    "        pdDfLastNormalTrainingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    " \n",
    "        # 读入比特同步的异常测试样本\n",
    "        pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"),\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        \n",
    "        # 读入解调器的有效状态参数，因为要利用它的帧同步锁\n",
    "        pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            fn_genIOrQSamples(\"I\")\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_genIOrQSamples(\"I\")\n",
    "            # Q路\n",
    "            fn_genIOrQSamples(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储分路之前的I/Q共有的需要正则化的属性名\n",
    "listNormIQFeatures = [\"IFU_OUTPUTLEVELSET\", \"IFU_INPUTLEVEL\", \"IFU_OUTPUTLEVEL\", \"IFU_INPUPORTTEMP\", \"IFU_OUTPUTPORTTEMP\",\\\n",
    "                    \"DEMOD_IFLEVEL\", \"DEMOD_EBNOVALUE\",\\\n",
    "                    \"DEMOD_CARRIEROFFSET\",\\\n",
    "                    \"DEMOD_BITRATE\", \"DEMOD_BITRATEOFFSET\", \"DEMOD_BITRATEOFFSETQCHL\"]\n",
    "listNormIFeatures = listNormIQFeatures + [\"DEMOD_VITERBI1TOTALBITNUMBER\", \"DEMOD_VITERBI1ERRORBITNUMBER\"]\n",
    "listNormQFeatures = listNormIQFeatures + [\"DEMOD_VITERBI2TOTALBITNUMBER\", \"DEMOD_VITERBI2ERRORBITNUMBER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listNormalTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        # 设置维特比译码的文件夹\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/vi\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路，把I路的需要正则化的数据转化成np数组后存入链表\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "                os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormIFeatures].values)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "            os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormIFeatures].values)\n",
    "            # Q路\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "            os.path.join(strSectionDir, \"Q/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormQFeatures].values)\n",
    "\n",
    "npNArrNormalTrainingSamples = np.concatenate(listNormalTrainingSamples)\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(npNArrNormalTrainingSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用正则化器正则化样本的需要正则化的属性，存入preprocessed文件夹。\n",
    "def fn_normalizeIOrQSamples(strIOrQ, listNormFeatures):\n",
    "    # 维特比译码的样本文件夹\n",
    "    strSamplesDir = os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/samples\")\n",
    "\n",
    "    # 正则化正常训练集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "    os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "    pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                                     index_col=\"RECTIME\")\n",
    "    if not pdDfNormalTrainingSamples.empty:\n",
    "        pdDfNormalTrainingSamples.loc[:, listNormFeatures] = \\\n",
    "            oMinMaxScaler.transform(pdDfNormalTrainingSamples.loc[:, listNormFeatures])\n",
    "        pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "    pdDfNormalTrainingSamples.to_csv(\\\n",
    "                                 os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                    index=False)\n",
    "\n",
    "    # 正则化异常测试集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "    os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "    pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                      index_col=\"RECTIME\")\n",
    "    if not pdDfAbnormalTestingSamples.empty:\n",
    "        pdDfAbnormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "            oMinMaxScaler.transform(pdDfAbnormalTestingSamples.loc[:, listNormFeatures])\n",
    "    pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                               os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index_label=\"RECTIME\")\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            fn_normalizeIOrQSamples(\"I\", listNormIFeatures)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_normalizeIOrQSamples(\"I\", listNormIFeatures)\n",
    "            # Q路\n",
    "            fn_normalizeIOrQSamples(\"Q\", listNormQFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 帧同步\n",
    "帧同步部分包含属性：DPU_FRAMELEN1（帧长）、DPU_FRAMEHEADLEN1（帧头长度）、DPU_RECEIVEDFRAMECOUNTER1（收帧计数）、DPU_DROPOUTFRAMECOUNTER1（丢帧计数）、DPU_TOTALBITNUMBER1（帧头总比特数）、DPU_ERRORBITNUMBER1（帧头误比特数）。其中DPU_FRAMELEN1、DPU_FRAMEHEADLEN1是预设值。其余皆为累加值，需要做差。这些属性均可正则化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据\n",
    "在parts/sync下新建frame文件夹。将数据存入frame中。该步结束后，文件结构如下：\n",
    "* parts/\n",
    "    * sync/\n",
    "        * frame/\n",
    "            * I(Q)/\n",
    "                * status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把帧同步部分的属性存一下。需要把两个通道分别存储\n",
    "listNewIFeatures = [\"DPU_FRAMELEN1\", \"DPU_FRAMEHEADLEN1\", \"DPU_RECEIVEDFRAMECOUNTER1\", \\\n",
    "                     \"DPU_DROPOUTFRAMECOUNTER1\", \"DPU_TOTALBITNUMBER1\", \"DPU_ERRORBITNUMBER1\"]\n",
    "listNewQFeatures = [\"DPU_FRAMELEN2\", \"DPU_FRAMEHEADLEN2\", \"DPU_RECEIVEDFRAMECOUNTER2\", \\\n",
    "                     \"DPU_DROPOUTFRAMECOUNTER2\", \"DPU_TOTALBITNUMBER2\", \"DPU_ERRORBITNUMBER2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/frame\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "        \n",
    "        # 只把帧同步部分新增的属性存入文件夹，因为后面产生样本和正则化的时候可以依照维特比译码\n",
    "        os.mkdir(os.path.join(strSectionDir, \"I\"))\n",
    "        pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "        pdDfStatus = pdDfValidStatus[listNewIFeatures]\n",
    "        pdDfStatus.to_csv(os.path.join(strSectionDir, \"I/status.csv\"), index_label=\"RECTIME\")\n",
    "        \n",
    "        os.mkdir(os.path.join(strSectionDir, \"Q\"))\n",
    "        pdDfStatus = pdDfValidStatus[listNewQFeatures]\n",
    "        pdDfStatus.to_csv(os.path.join(strSectionDir, \"Q/status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算每秒的比特数和帧数\n",
    "该步完成后，文件结构如下：\n",
    "* frame/\n",
    "    * I(Q)/\n",
    "        * status.csv\n",
    "        * diff/\n",
    "            * status.csv\n",
    "            \n",
    "发现DPU_DROPOUTFRAMECOUNTER1似乎不是一个累积量，因为再很多任务里面，它的值一直不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存入比特数和帧数的属性名\n",
    "listAggreIFeatures = [\"DPU_RECEIVEDFRAMECOUNTER1\", \\\n",
    "                     \"DPU_TOTALBITNUMBER1\", \"DPU_ERRORBITNUMBER1\"]\n",
    "listAggreQFeatures = [\"DPU_RECEIVEDFRAMECOUNTER2\", \\\n",
    "                     \"DPU_TOTALBITNUMBER2\", \"DPU_ERRORBITNUMBER2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只在维特比译码阶段出现了累积量\n",
    "def fn_subNumber(nWin):\n",
    "        if nWin.size == 1:\n",
    "            return  nWin[0]\n",
    "        elif nWin[1] < nWin[0]:\n",
    "                return nWin[1]\n",
    "        else:\n",
    "                return nWin[1] - nWin[0]\n",
    "\n",
    "# 把0元素全部改为它的上一个元素的值\n",
    "def fn_fillZeros(nWin):\n",
    "    if nWin.size == 1:\n",
    "        return nWin[0]\n",
    "    elif nWin[1] == 0:\n",
    "        return nWin[0]\n",
    "    else:\n",
    "        return nWin[1]\n",
    "\n",
    "# 对状态函数做差。输入状态的通道文件夹，和需要做差的属性，完成做差，存入diff\n",
    "def fn_subIOrQ(strDir, listAggreFeatures):\n",
    "    # 清空diff\n",
    "    strDiffDir = os.path.join(strDir, \"diff\")\n",
    "    if os.path.exists(strDiffDir):\n",
    "        shutil.rmtree(strDiffDir)\n",
    "    os.mkdir(strDiffDir)\n",
    "    pdDfStatus = pd.read_csv(os.path.join(strDir, \"status.csv\"), index_col=\"RECTIME\")\n",
    "    # 从第二个有效上报时间点开始，算每个点单独的包数\n",
    "    pdDfStatus[listAggreFeatures] = pdDfStatus[listAggreFeatures].rolling(window=2, min_periods=1).\\\n",
    "    apply(fn_subNumber, raw=True)\n",
    "    # 找到第一个有效时间点之前的时间点的整数坐标\n",
    "    strFirstValidIndex = pdDfStatus.index[0]\n",
    "    i = 0\n",
    "    for strIndex in pdDfRawStatus.index:\n",
    "        if strIndex == strFirstValidIndex:\n",
    "            # 取出第一个有效时间点之前的记录和第一个有效时间点记录\n",
    "            pdSeriesRaw = pdDfRawStatus.loc[pdDfRawStatus.index[i - 1], listAggreFeatures]\n",
    "            pdSeriesToBeCulled = pdDfStatus.loc[strFirstValidIndex, listAggreFeatures]\n",
    "            for j in range(len(pdSeriesToBeCulled)):\n",
    "                # 如果第一个有效点记录的在某域上的值大于等于相应的第一个有效时间点之前的记录的值，则做差\n",
    "                pdSeriesToBeCulled[j] = pdSeriesToBeCulled[j] - pdSeriesRaw[j] \\\n",
    "                    if pdSeriesToBeCulled[j] >= pdSeriesRaw[j] else pdSeriesToBeCulled[j]\n",
    "            pdDfStatus.loc[strFirstValidIndex, listAggreFeatures] = pdSeriesToBeCulled\n",
    "        i += 1\n",
    "    # 填充0值\n",
    "    pdDfStatus[listAggreFeatures] = pdDfStatus[listAggreFeatures].rolling(window=2, min_periods=1).\\\n",
    "    apply(fn_fillZeros, raw=True)\n",
    "    pdDfStatus.to_csv(os.path.join(strDiffDir, \"status.csv\"), index_label=\"RECTIME\")\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 读入原始状态参数\n",
    "        pdDfRawStatus = pd.read_csv(os.path.join(strDemodDir, \"raw/status.csv\"), index_col=\"RECTIME\")\n",
    "        # 读入控制参数文件\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        # 如果分路则做Q路\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 分路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/frame/I\"), listAggreIFeatures)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/frame/I\"), listAggreIFeatures)\n",
    "            # Q路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/frame/Q\"), listAggreQFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依照维特比同步生成样本\n",
    "def fn_genIOrQSamples(strIOrQ):\n",
    "    # 导入帧同步部分的数据。注意应该在diff文件夹下导入\n",
    "    pdDfStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/frame/\" + strIOrQ + \"/diff/status.csv\"),\\\n",
    "                                   index_col=\"RECTIME\")\n",
    "\n",
    "    # 清空帧同步部分样本文件夹\n",
    "    strSamplesDir = os.path.join(strDemodDir, \"parts/sync/frame/\" + strIOrQ + \"/samples\")        \n",
    "    if os.path.exists(strSamplesDir):\n",
    "        shutil.rmtree(strSamplesDir)\n",
    "    os.mkdir(strSamplesDir)\n",
    "    # 设置维特比译码样本文件夹\n",
    "    strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/samples\")\n",
    "\n",
    "    # 正常样本\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal\"))\n",
    "    # 正常训练样本\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "    # 读入输入部分正常训练样本的index\n",
    "    pdDfLastNormalTrainingSamples = pd.read_csv(\\\n",
    "                         os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                         index_col=\"RECTIME\")\n",
    "    # 选取正常训练样本的index\n",
    "    pdDfNormalTrainingSamples = \\\n",
    "        pdDfStatus.loc[pdDfLastNormalTrainingSamples.index, :]\n",
    "    pdDfNormalTrainingSamples.to_csv(\\\n",
    "                           os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                           index_label=\"RECTIME\")\n",
    "\n",
    "\n",
    "\n",
    "    # 异常样本\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "    # 读入输入部分异常测试样本的index\n",
    "    pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                 index_col=\"RECTIME\")\n",
    "    pdDfAbnormalTestingSamples = \\\n",
    "    pdDfStatus.loc[pdDfLastAbnormalTestingSamples.index, :]\n",
    "    pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                                os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                index_label=\"RECTIME\")\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            fn_genIOrQSamples(\"I\")\n",
    "        else:\n",
    "            # 分路\n",
    "            fn_genIOrQSamples(\"I\")\n",
    "            fn_genIOrQSamples(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化\n",
    "帧同步新增的所有属性都需要正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listNormalTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        # 设置维特比译码的文件夹\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/frame\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路，把I路的需要正则化的数据转化成np数组后存入链表\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "                os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples.values)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "            os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples.values)\n",
    "            # Q路\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "            os.path.join(strSectionDir, \"Q/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples.values)\n",
    "\n",
    "npNArrNormalTrainingSamples = np.concatenate(listNormalTrainingSamples)\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(npNArrNormalTrainingSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用正则化器正则化样本的需要正则化的属性，和维特比译码的正则化结果组合后，存入preprocessed文件夹。\n",
    "def fn_normalizeIOrQSamples(strIOrQ):\n",
    "    # 帧同步的样本文件夹\n",
    "    strSamplesDir = os.path.join(strDemodDir, \"parts/sync/frame/\" + strIOrQ + \"/samples\")\n",
    "    # 维特比译码的样本文件夹\n",
    "    strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/samples\")\n",
    "\n",
    "    # 正则化正常训练集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "    os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "    pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                index_col=\"RECTIME\")\n",
    "    if not pdDfNormalTrainingSamples.empty:\n",
    "        pdDfNormalTrainingSamples.loc[:, :] = \\\n",
    "            oMinMaxScaler.transform(pdDfNormalTrainingSamples)\n",
    "        # 因为预处理后的中频控制部分状态没有index，所以为了join，必须把这儿的index去掉\n",
    "        pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "    pdDfLastPreprocessedNormalTrainingSamples = pd.read_csv(\\\n",
    "                                  os.path.join(strLastSamplesDir, \"normal/train/preprocessed/samples.csv\"))\n",
    "    pdDfPreprocessedNormalTrainingSamples = pdDfLastPreprocessedNormalTrainingSamples.join(\\\n",
    "                                  pdDfNormalTrainingSamples)\n",
    "    pdDfPreprocessedNormalTrainingSamples.to_csv(\\\n",
    "                                  os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                   index=False)\n",
    "\n",
    "\n",
    "    # 正则化正常测试集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "    os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "    pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                index_col=\"RECTIME\")\n",
    "    if not pdDfAbnormalTestingSamples.empty:\n",
    "        pdDfAbnormalTestingSamples.loc[:, :] = \\\n",
    "            oMinMaxScaler.transform(pdDfAbnormalTestingSamples)\n",
    "    pdDfLastPreprocessedAbnormalTestingSamples = pd.read_csv(\\\n",
    "                             os.path.join(strLastSamplesDir, \"abnormal/preprocessed/samples.csv\"),\\\n",
    "                             index_col=\"RECTIME\")\n",
    "    pdDfPreprocessedAbnormalTestingSamples = pdDfLastPreprocessedAbnormalTestingSamples.join(\\\n",
    "                                pdDfAbnormalTestingSamples)\n",
    "    pdDfPreprocessedAbnormalTestingSamples.to_csv(\\\n",
    "                                os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                index_label=\"RECTIME\")\n",
    "    \n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            fn_normalizeIOrQSamples(\"I\")\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_normalizeIOrQSamples(\"I\")\n",
    "            # Q路\n",
    "            fn_normalizeIOrQSamples(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去噪\n",
    "利用pca去噪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "画出散点图，不同颜色对应不同的类别的样本\n",
    "输入一个每一行对应的一个样本被pca过后的向量的矩阵。\n",
    "输入一个对应series标签\n",
    "\"\"\"\n",
    "def fn_plotScatter(pdDfX, pdSeriesY):\n",
    "    pdDfTempX = pdDfX.iloc[:, 0:1]\n",
    "    pdDfTempX = pd.concat((pdDfTempX, pdSeriesY), axis=1, join=\"inner\")\n",
    "    pdDfTempX.columns = [\"First  Vector\", \"Second Vector\", \"Label\"]\n",
    "    sns.lmplot(x=\"First Vector\", y=\"Second Vector\", hue=\"Label\",\\\n",
    "          data=pdDfTempX, fit_reg=False)\n",
    "    ax = plt.gca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算异常分数的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "输入原始的样本矩阵和用重构的样本矩阵，输出每个样本对应的异常分数。\n",
    "分数越接近1越异常，越接近0越正常\n",
    "\"\"\"\n",
    "def fn_anomalyScores(pdDfOriginal, pdDfRecon):\n",
    "    loss = np.sum((np.array(pdDfOriginal) - np.array(pdDfRecon)) ** 2, axis=1)\n",
    "    loss = pd.Series(data=loss, index=pdDfOriginal.index)\n",
    "    loss = (loss - np.min(loss)) / (np.max(loss) - np.min(loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca\n",
    "要先做尺度缩放，缩放到0-1之间。用pca对正常训练样本做降维。然后重构样本，做出重构误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "读入帧同步的所有正常训练样本\n",
    "由于正常测试样本都是正则化之后的训练样本，没有对应的index。在读入正常训练样本\n",
    "的同时，需要读入它们对应的index\n",
    "\"\"\"\n",
    "listSamples = []\n",
    "listIndexes = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/frame\")\n",
    "        # 不能先读I路，因为I路和Q路的特征参数有后缀名做区分\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            pdDfSamples = pd.read_csv(os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"),\\\n",
    "                  index_col=\"RECTIME\")\n",
    "            pdDfPreprocessedSamples = \\\n",
    "                pd.read_csv(os.path.join(strSectionDir, \"I/samples/normal/train/preprocessed/samples.csv\"))\n",
    "            listSamples.append(pdDfPreprocessedSamples.values)\n",
    "            listIndexes.extend([(strDemodDir, strIndex, 1) for strIndex in pdDfSamples.index])\n",
    "        else:\n",
    "            # 分路，读入两路数据\n",
    "            pdDfSamples = pd.read_csv(os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"),\\\n",
    "                  index_col=\"RECTIME\")\n",
    "            pdDfPreprocessedSamples = \\\n",
    "                pd.read_csv(os.path.join(strSectionDir, \"I/samples/normal/train/preprocessed/samples.csv\"))\n",
    "            listSamples.append(pdDfPreprocessedSamples.values)\n",
    "            listIndexes.extend([(strDemodDir, strIndex, 1) for strIndex in pdDfSamples.index])\n",
    "            \n",
    "            pdDfSamples = pd.read_csv(os.path.join(strSectionDir, \"Q/samples/normal/train/samples.csv\"),\\\n",
    "                  index_col=\"RECTIME\")\n",
    "            pdDfPreprocessedSamples = \\\n",
    "                pd.read_csv(os.path.join(strSectionDir, \"Q/samples/normal/train/preprocessed/samples.csv\"))\n",
    "            listSamples.append(pdDfPreprocessedSamples.values)\n",
    "            listIndexes.extend([(strDemodDir, strIndex, 1) for strIndex in pdDfSamples.index])\n",
    "\n",
    "npNArrSamples = np.concatenate(listSamples)\n",
    "# 注意，这里的样本矩阵没有列名\n",
    "pdDfSamples = pd.DataFrame(data=npNArrSamples, index=pd.Series(data=listIndexes, name=\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建pca\n",
    "pca = PCA(n_components=24, whiten=False, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做pca\n",
    "npNArrPca = pca.fit_transform(pdDfSamples.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar(range(1, pca.explained_variance_ratio_.shape[0] + 1), np.cumsum(pca.explained_variance_ratio_))\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(np.arange(0, 1., 0.05))\n",
    "ax.set_xticks(np.arange(1, 25, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5, whiten=False, random_state=2020)\n",
    "npNArrPca = pca.fit_transform(pdDfSamples.iloc[:, 0:5].values)\n",
    "pdDfInverse = pd.DataFrame(data=pca.inverse_transform(npNArrPca), index=pdDfSamples.index, \\\n",
    "   columns=pdDfSamples.iloc[:, 0:5].columns)\n",
    "pdSeriesLoss = fn_anomalyScores(pdDfSamples.iloc[:, 0:5], pdDfInverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "oKMeans = KMeans(n_clusters=2)\n",
    "npNArrIndexes = oKMeans.fit_predict(npNArrPca[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20878"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(npNArrIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(range(pdSeiresLoss.size), pdSeriesLoss.sort_values(), s=5)\n",
    "ax = plt.gca()\n",
    "_ = ax.set_xticks(range(0, pdSeiresLoss.size, 2000))\n",
    "plt.vlines(20400, 0, 1, linestyles=\"--\", colors=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "fThreshold = pdSeiresLoss.sort_values()[20400]\n",
    "pdDfLeftSamples = pdDfSamples.loc[pdSeiresLoss < fThreshold, :]\n",
    "pdDfBadSamples = pdDfSamples.loc[pdSeiresLoss > fThreshold, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将剔除异常样本的正常训练样本划分为各个部分\n",
    "存入各个部分对应的文件中，以部分名命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0-4 中频控制\n",
    "5-6 中频输入\n",
    "7-8 载波同步\n",
    "9-13 比特同步\n",
    "14-17 维特比译码\n",
    "18-23 帧同步\n",
    "\"\"\"\n",
    "pdDfLeftSamples.iloc[:, 0:5].to_csv(\"../left/ifu.csv\", index_label=\"id\")\n",
    "pdDfLeftSamples.iloc[:, 0:7].to_csv(\"../left/input.csv\", index_label=\"id\")\n",
    "pdDfLeftSamples.iloc[:, 0:9].to_csv(\"../left/ifu.csv\", index_label=\"id\")\n",
    "pdDfLeftSamples.iloc[:, 0:14].to_csv(\"../left/ifu.csv\", index_label=\"id\")\n",
    "pdDfLeftSamples.iloc[:, 0:18].to_csv(\"../left/ifu.csv\", index_label=\"id\")\n",
    "pdDfLeftSamples.iloc[:, :].to_csv(\"../left/ifu.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 译码部分\n",
    "DPU_DECODEPOS为0则解扰在译码前、1则解扰在译码后。由于crc只能起到校验的作用，所以不管crc，只考虑ldpc和rs。ldpc和rs两者不会同时存在。目前打算用聚类的方法，将译码部分的记录分成正常和异常两部分，可能样本含量多的cluster代表正常样本、反之为异常样本。\n",
    "\n",
    "DPU_SYNCTHRESHOLD2、DPU_CTLTHRESHOLD2、DPU_LTSTHRESHOLD2、DPU_BITSLIPWINDOW2这四个参数是在帧同步时需要设定的参数，但是在整个数据集里它们的值均为3。所以目前暂时不考虑它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据\n",
    "在parts下新建decode文件夹。译码也是分为两个通道进行的，所以要在decode下新建ch1和ch2文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
