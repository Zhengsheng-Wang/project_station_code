{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fn_getSamples(bPositive, strPart, strJobsDir):\n",
    "    npNArrTotalSamples = []\n",
    "    for name in os.listdir(strJobsDir):\n",
    "        strJobDir = os.path.join(strJobsDir, name)\n",
    "        npNArrJobSamples = fn_getSamplesFromAJob(bPositive, strPart, strJobDir)\n",
    "        for npNArr in npNArrJobSamples:\n",
    "            npNArrTotalSamples.append(npNArr)\n",
    "    \n",
    "    npSamples = np.array(npNArrTotalSamples)\n",
    "    return npSamples\n",
    "        \n",
    "        \n",
    "def fn_getSamplesFromAJob(bPositive, strPart, strJobDir):\n",
    "    npNArrSamples = []\n",
    "    strSpecificDir = \"\"\n",
    "    if bPositive:\n",
    "        strSpecificDir = os.path.join(strJobDir, \"samples/positive\")\n",
    "    else:\n",
    "        strSpecificDir = os.path.join(strJobDir, \"samples/negtive\")\n",
    "        \n",
    "    for name in os.listdir(strSpecificDir):\n",
    "        strStatusDir = os.path.join(strSpecificDir, name)\n",
    "        strSectionsDir = os.path.join(strStatusDir, \"sections\")\n",
    "        for name in os.listdir(strSectionsDir):\n",
    "            if name == strPart:\n",
    "                strSectionDir = os.path.join(strSectionsDir, name)\n",
    "                npNArr = np.load(os.path.join(strSectionDir, \"status.npy\"))\n",
    "                npNArrSamples.append(npNArr)\n",
    "                break\n",
    "                \n",
    "    return npNArrSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GANOperator(object):\n",
    "    def __init__(self, nLatentDim, nHiddenDimG, nHiddenDimD, nSeqLength, nBatchSize, nFeatures, npNArrSample):\n",
    "        self.nHiddenDimG = nHiddenDimG\n",
    "        self.nHiddenDimD = nHiddenDimD\n",
    "        self.nSeqLength = nSeqLength\n",
    "        self.nBatchSize = nBatchSize\n",
    "        self.nFeatures = nFeatures\n",
    "        \n",
    "        self.npNArrSample = npNArrSample\n",
    "        self.oSeqTrainableDiscriminator = fn_makeDiscriminatorTrainable()\n",
    "        self.oSeqTrainableAdversarial = fn_makeAdversarialTrainable()\n",
    "        self.oSeqGenerator = fn_makeGenerator()\n",
    "\n",
    "        \n",
    "    def fn_makeGenerator(self):\n",
    "        if self.oSeqGenerator:\n",
    "            return self.oSeqGenerator\n",
    "        self.oSeqGenerator = Sequential()\n",
    "        self.oSeqGenerator.add(GRU(nHiddenDimG, dropout = 0.1, recurrent_dropout = 0.5, return_sequences = True))\n",
    "        self.oSeqGenerator.add(Dense(nFeatures, activation = math.tanh))\n",
    "        return self.oSeqGenerator\n",
    "    \n",
    "    def fn_makeDiscriminator(self):\n",
    "        if self.oSeqDiscriminator:\n",
    "            return self.oSeqDiscriminator\n",
    "        self.oSeqDiscriminator = Sequential()\n",
    "        self.oSeqDiscriminator.add(GRU(nHiddenDimD, dropout = 0.1, recurrent_dropout = 0.5, return_sequences = True))\n",
    "        self.oSeqDiscriminator.add(Dense(nFeatures))\n",
    "        return self.oSeqDiscriminator\n",
    "    \n",
    "    def fn_DLoss(tensorTrue, tensorPred):\n",
    "        nRow = tensorTrue.shape[0]\n",
    "        nRow = nRow / 2\n",
    "        tensorOnes, tensorReal = tensorTrue[:nRow, :], tensorPred[:nRow, :]\n",
    "        tensorZeros, tensorFake = tensorTrue[nRow:, :], tensorPred[nRow:, :]\n",
    "        \n",
    "        tensorLossReal = math.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = tensorReal, labels = tensorOnes), 1)\n",
    "        tensorLossFake = math.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = tensorFake, labels = tensorZeros), 1)\n",
    "        tensorLoss = tensorLossReal + tensorLossFake\n",
    "        return math.reduce_mean(tensorLoss)\n",
    "        \n",
    "    def fn_GLoss(tensorTrue, tensorPred):\n",
    "        tensorLoss = math.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = tensorPred, labels = tensorTrue), 1)\n",
    "        return math.reduce_mean(tensorLoss)\n",
    "    \n",
    "    def fn_makeDiscriminatorTrainable(self):\n",
    "        if self.oSeqTrainableDiscriminator:\n",
    "            return self.oSeqTrainableDiscriminator\n",
    "        oOptimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "        self.oSeqTrainableDiscriminator = Sequential()\n",
    "        self.oSeqTrainableDiscriminator.add(self.fn_makeDiscriminator())\n",
    "        self.oSeqTrainableDiscriminator.compile(loss=fn_DLoss, optimizer=oOptimizer, metrics=[\"accuracy\"])\n",
    "        return self.oSeqTrainableDiscriminator\n",
    "    \n",
    "    def fn_makeAdversarialTrainable(self):\n",
    "        if self.oSeqTrainableAdversarial:\n",
    "            return self.oSeqTrainableAdversarial\n",
    "        oOptimer = tf.optimizers.Adam()\n",
    "        self.oSeqTrainableAdversarial = Sequential()\n",
    "        self.oSeqTrainableAdversarial.add(self.fn_makeGenerator())\n",
    "        self.oSeqTrainableAdversarial.add(self.fn_makeDiscriminator())\n",
    "        self.oSeqTrainableAdversarial.compile(loss = fn_GLoss, optimizer=oOptimer, metrics=[\"accuracy\"])\n",
    "        return self.oSeqTrainableAdversarial\n",
    "    \n",
    "    def fn_train(self, nEpochs = 2000, nBatchSize = 256):\n",
    "        for epoch in range(nEpochs):\n",
    "            npNArrSample = self.npNArrSample[np.random.randint(0, self.npNArrSample.shape[0], size = nBatchSize), :, :]\n",
    "            npNoise = np.random.uniform(-1.0, 1.0, size = [nBatchSize, nSeqLength, nLatentDim])\n",
    "            npNArrFake = oSeqGenerator.predict(npNoise)\n",
    "            npNArrX = np.concatenate((npNArrSample, npNArrFake))\n",
    "            npNArrY = np.ones([2 * nBatchSize, 1])\n",
    "            npNArrY[nBatchSize:, :] = 0\n",
    "            fLossD = oSeqTrainableDiscriminator.train_on_batch(npNArrX, npNArrY)\n",
    "            \n",
    "            npNArrY = np.ones([nBatchSize, 1])\n",
    "            npNoise = np.random.uniform(-1.0, 1.0, size = [nBatchSize, 100])\n",
    "            fLossA = oSeqTrainableAdversarial.train_on_batch(npNoise, npNArrY)\n",
    "\n",
    "            strMsg = \"%d: [D loss: %f, acc: %f]\" % (i, fLossD[0], fLossD[1])\n",
    "            strMsg = \"%s [A loss: %f, acc: %f]\" % (strMsg, fLossA[0], fLossA[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.95965273, -0.56959686, -0.66869449,  0.36588037],\n",
       "        [-0.13474461, -0.00982187,  0.33888038, -0.82310457],\n",
       "        [ 0.15054734,  0.99423397, -0.22550095,  0.81209248]],\n",
       "\n",
       "       [[ 0.86594201, -0.5032699 ,  0.65057817, -0.14016409],\n",
       "        [-0.39339544,  0.33758776, -0.25818414, -0.22497899],\n",
       "        [ 0.47629576, -0.83481436, -0.0445314 ,  0.66225107]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(-1.0, 1.0, size = [2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class operator(object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
