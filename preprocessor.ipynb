{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入包和设置全局路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import lxml.etree as etree\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 设置路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "strJobsDir = \"../jobs_test\"\n",
    "strZipsDir = \"../zips\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读入任务配置文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入任务计划文件\n",
    "\n",
    "首先清空jobs文件夹。\\\n",
    "WorkSch文件中存放了提前计算出的预计接收开始和结束时间。需利用这个接收开始和结束时间截取出有效时间段。\\\n",
    "可能有多个WorkSch文件，根据它的createdTime选择最新的WorkSch文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(strJobsDir):\n",
    "    shutil.rmtree(strJobsDir)\n",
    "os.mkdir(strJobsDir)\n",
    "for strZipFileName in os.listdir(strZipsDir):\n",
    "    pdTimestampNewestCreated = pd.Timestamp(\"1970-1-1\")\n",
    "    strJobDir = os.path.join(strJobsDir, os.path.splitext(strZipFileName)[0])\n",
    "    os.mkdir(strJobDir)\n",
    "    strZipFile = os.path.join(strZipsDir, strZipFileName)\n",
    "    with zipfile.ZipFile(strZipFile) as oZipFile:\n",
    "        for strFile in oZipFile.namelist():\n",
    "            if \"WorkSch_TASK\" in strFile:\n",
    "                strWorkSchFile = os.path.join(strJobDir, \"work_sch.xml\")\n",
    "                with oZipFile.open(strFile) as f:\n",
    "                    oElementTree = etree.parse(f)\n",
    "                    # f 文件对象只能在parse中使用一次\n",
    "                    # 找到文件创建时间\n",
    "                    pdTimestampCreated = pd.Timestamp(\n",
    "                            oElementTree.find(\"./fileHeader/createdTime\").text)\n",
    "                    if pdTimestampCreated > pdTimestampNewestCreated:\n",
    "                    # 提取最新的文件\n",
    "                        pdTimestampNewestCreated = pdTimestampCreated\n",
    "                        oElementTree.write(strWorkSchFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入设备列表文件\n",
    "任务所用的所有设备都在列表文件里。要根据文件中对设备状态文件的属于的设备的描述提取出用于数据接收传输的设备状态文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strZipFileName in os.listdir(strZipsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, os.path.splitext(strZipFileName)[0])\n",
    "    strZipFile = os.path.join(strZipsDir, strZipFileName)\n",
    "    with zipfile.ZipFile(strZipFile) as oZipFile:\n",
    "        for strFile in oZipFile.namelist():\n",
    "            if \"DeviceList\" in strFile:\n",
    "                strDeviceListFile = os.path.join(strJobDir, \"device_list.xml\")\n",
    "                with oZipFile.open(strFile) as f:\n",
    "                    with open(strDeviceListFile, \"wb\") as f1:\n",
    "                        f1.write(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解调器预处理描述\n",
    "\n",
    "1. 根据任务的设备列表文件找到解调器的设备ID\n",
    "2. 利用设备ID找到解调器的设备状态文件和控制文件，并保存\n",
    "3. 从任务的任务计划文件中读出接收的开始和结束时间，利用接收时间段截取出有效时间段内的记录\n",
    "4. 将解调器的状态参数按照信号处理流程划分为数个最小模块\n",
    "5. 针对每个最小模块产生训练样本和测试样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入设备状态文件和控制文件\n",
    "\n",
    "1. 清空原有的设备文件夹。\n",
    "2. 在设备列表文件中找到解调器设备ID\n",
    "3. 将相应设备状态文件载入设备文件夹\n",
    "\n",
    "执行完成后，任务文件夹里多出如下文件：\n",
    "* 任务名/\n",
    "    * 解调器名/\n",
    "        * raw/\n",
    "            * status.csv\n",
    "        * control.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从zip文件中解压缩具有设备的状态文件，存入raw\n",
    "def fn_extractFilesFromAZip(strJobDir, strID, strZipFile):\n",
    "    strZipDemodStatusFile = \"Status_\" + strID\n",
    "    with zipfile.ZipFile(strZipFile) as oZipFile:\n",
    "        for strFile in oZipFile.namelist():\n",
    "            # 迭代找到zip文件里的解调器的状态文件和控制参数文件\n",
    "            if \"Status_\" + strID in strFile:\n",
    "                # 状态文件\n",
    "                with oZipFile.open(strFile) as f:\n",
    "                    with open(os.path.join(strJobDir, strID + \"/raw/status.csv\"), \"wb\") as f1:\n",
    "                        f1.write(f.read())\n",
    "            elif \"Control_\" + strID in strFile:\n",
    "                # 控制文件\n",
    "                with oZipFile.open(strFile) as f:\n",
    "                    with open(os.path.join(strJobDir, strID + \"/control.csv\"), \"wb\") as f1:\n",
    "                        f1.write(f.read())\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    # 删除原有的解调器文件夹\n",
    "    for strName in os.listdir(strJobDir):\n",
    "        if \"Demod\" in strName:\n",
    "            strDemodDir = os.path.join(strJobDir, strName)\n",
    "            shutil.rmtree(strDemodDir)\n",
    "    \n",
    "    strZipFile = os.path.join(strZipsDir, strJob + \".zip\")\n",
    "    strDeviceListFile = os.path.join(strJobDir, \"device_list.xml\")\n",
    "    oElementTree = etree.parse(strDeviceListFile)\n",
    "    listDevElement = oElementTree.findall(\"./content/deviceList/Device\")\n",
    "    for oElement in listDevElement:\n",
    "        strID = oElement.find(\"DevID\").text\n",
    "        if \"Demod\" in strID:\n",
    "            # 新建解调器文件raw文件夹\n",
    "            os.makedirs(os.path.join(strJobDir, strID + \"/raw\"))\n",
    "            fn_extractFilesFromAZip(strJobDir, strID, strZipFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解调器属性选取（更新）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查所有的解调器状态文件发现，以下属性不是所有的解调器都存在：\n",
    "\n",
    "DEMOD_PHASEROTATION，GLOBAL_DEMOD1STATUS，GLOBAL_TEMPSTATUS，DRU_DISKSPACE1，DRU_USEDSPACE1，DRU_FREESPACE1，DRU_USEDPERCENT1\n",
    "\n",
    "对它们进行忽略。\n",
    "\n",
    "目前发现的在数据集中的值只有一种的属性也全部忽略。以后可能会发现它们有多种值。\n",
    "\n",
    "解调器的状态参数按照参数名的前缀来划分大致有3类——DPU（data packet unit），DEMOD、IFU(中频控制单元)，DRU。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的函数完成的功能如下：\n",
    "* 输入查询的状态参数名称，以字符串形式返回数据集中该参数所具有的所有值组成的集合\n",
    "* 输入任务设定的参数名和对应的值，返回其它任务设定参数的值和该值的对应关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询的状态参数所有可能值\n",
    "def fn_getValuesInStr(strFeature):\n",
    "    setCat = set()\n",
    "    for strJob in os.listdir(strJobsDir):\n",
    "        strJobDir = os.path.join(strJobsDir, strJob)\n",
    "        listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "        for strDemodDir in listDemodDirs:\n",
    "            try:\n",
    "                pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "                for r in pdDfValidStatus.loc[:, strFeature]:\n",
    "                    setCat.add(r)\n",
    "            except:\n",
    "                # 如果该文件里没有查询的参数名，输出文件名\n",
    "                print(strDemodDir)\n",
    "    return str(setCat)\n",
    "\n",
    "# 输出参数具有某一个值的解调器文件夹\n",
    "def fn_getDirOfAValue(strFeature, value):\n",
    "    for strJob in os.listdir(strJobsDir):\n",
    "        listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "        for strDemodDir in listDemodDirs:\n",
    "            pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "            if value in list(pdDfValidStatus.loc[:, strFeature]):\n",
    "                return strDemodDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{0, 1}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_getValuesInStr(\"DPU_RSENABLE1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../jobs\\\\JOB201912276594418\\\\KJ_HDemodQH1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_getDirOfAValue(\"DPU_RSENABLE1\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 截取出有效接收时间范围内的记录\n",
    "\n",
    "1. 首先清空每个解调器文件夹下的valid文件夹\n",
    "2. 然后从work_sch.xml文件中读入数据接收的有效时间段\n",
    "3. 根据有效时间段截取每个解调器的设备状态文件的有效记录，存入valid文件夹\n",
    "执行完成后，任务文件里多出了如下文件：\n",
    "* 任务名/\n",
    "    * 解调器名/\n",
    "        * valid/\n",
    "            * status.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从指定任务文件夹中读取任务所使用的解调器名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从任务文件夹中提取计划的接收任务开始时间和结束时间\n",
    "def fn_getValidPeriod(strJobDir):\n",
    "    strWorkSchFile = os.path.join(strJobDir, \"work_sch.xml\")\n",
    "    oElementTree = etree.parse(strWorkSchFile)\n",
    "    strReceivingStartTime = \"./content/equipmentInfo/receivingStartTime\"\n",
    "    strReceivingEndTime = \"./content/equipmentInfo/receivingEndTime\"\n",
    "    pdTimestampStart = pd.Timestamp(oElementTree.find(strReceivingStartTime).text)\n",
    "    pdTimestampEnd = pd.Timestamp(oElementTree.find(strReceivingEndTime).text)\n",
    "    return pdTimestampStart, pdTimestampEnd\n",
    "\n",
    "# 利用任务的计划接收开始和结束时间截取解调器的有效状态\n",
    "def fn_extractValidRecordsOfRawStatus(pdTimestampStart, pdTimestampEnd, strStatusDir):\n",
    "    strValidStatusDir = os.path.join(strStatusDir, \"valid\")\n",
    "    if os.path.exists(strValidStatusDir):\n",
    "            shutil.rmtree(strValidStatusDir)\n",
    "    os.mkdir(strValidStatusDir)\n",
    "\n",
    "    strRawStatusFile = os.path.join(strStatusDir, \"raw/status.csv\")\n",
    "    pdDfRawStatus = pd.read_csv(strRawStatusFile, index_col=\"RECTIME\")\n",
    "    pdSeriesFilter = pd.Series(data=pdDfRawStatus.index)\n",
    "    pdSeriesFilter = pdSeriesFilter.apply(lambda t: pd.Timestamp(t))\n",
    "    # 在用值为bool的series作为索引之前，要把series转化为list\n",
    "    pdIndexSeries = (pdSeriesFilter >= pdTimestampStart) & (pdSeriesFilter <= pdTimestampEnd)\n",
    "    pdDfFiltered = pdDfRawStatus.loc[pdIndexSeries.values, :]\n",
    "    strValidStatusFile = os.path.join(strValidStatusDir, \"status.csv\")\n",
    "    pdDfFiltered.to_csv(strValidStatusFile, index_label=\"RECTIME\")\n",
    "\n",
    "# 截取\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    tuplepdTimestamps = fn_getValidPeriod(strJobDir)\n",
    "\n",
    "    liststrDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in liststrDemodDirs:\n",
    "        fn_extractValidRecordsOfRawStatus(tuplepdTimestamps[0],tuplepdTimestamps[1], strDemodDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过输入的任务文件夹返回任务文件夹中的所有解调器文件夹路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_getDemodDirsOfAJob(strJobDir):\n",
    "    liststrDemodDirs = [os.path.join(strJobDir, strName) for strName in os.listdir(strJobDir) if \"Demod\" in strName]\n",
    "    return liststrDemodDirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分描述\n",
    "解调译码过程按照信号处理流程包含如下阶段：\n",
    "* 中频控制\n",
    "* 中频输入\n",
    "* 载波同步\n",
    "* 比特同步\n",
    "* 维特比译码（I/Q路）\n",
    "* 帧同步（I/Q路）\n",
    "* 译码和解扰（I/Q路）\n",
    "任务分为I/Q分路和I/Q合路：\n",
    "* 合路：在维特比译码前，将I和Q路进行并串转换，对转换后的串行信号进行维特比译码即后续操作\n",
    "* 分路：分别对I路和Q路进行维特比译码及后续操作\n",
    "\n",
    "故障诊断的思想：\n",
    "\n",
    "对于一条记录来说，如果在信号处理的某一阶段之前各个阶段的状态参数反映的状态正常，但加上这一阶段的状态参数后，反映的状态不正常，则可说明后面加上去的那一阶段的参数不正常。这样一来，定位出了这个故障记录发生故障的具体阶段。\n",
    "\n",
    "按照这一思想，组合解调译码过程的各个阶段成如下部分：\n",
    "1. 中频控制\n",
    "2. 中频控制、中频输入\n",
    "3. 中频控制，中频输入、载波同步\n",
    "4. 中频控制、中频输入、载波同步、比特同步\n",
    "5. I路：中频控制、中频输入、载波同步、比特同步、维特比译码（I路）\n",
    "6. Q路：中频控制、中频输入、载波同步、比特同步、维特比译码（Q路）\n",
    "7. I路：中频控制、中频输入、载波同步、比特同步、维特比译码（I路）、帧同步（I路）\n",
    "8. Q路：中频控制、中频输入、载波同步、比特同步、维特比译码（Q路）、帧同步（Q路）\n",
    "9. I路：中频控制、中频输入、载波同步、比特同步、维特比译码（I路）、帧同步（I路）、译码和解扰（I路）\n",
    "10. Q路：中频控制、中频输入、载波同步、比特同步、维特比译码（Q路）、帧同步（Q路）、译码和解扰（Q路）\n",
    "\n",
    "可以把一条记录的参数分解成以上各个部分，其中部分2的中频控制参数即为部分1的参数，部分3的中频控制和中频输入部分的参数即为部分2的参数，以此类推。比如：一条异常记录的部分1的参数正常，但部分2的参数异常，则可说明该记录的异常出现在中频输入。\n",
    "\n",
    "一条记录可以产生的样本数并不唯一。一条记录对应于1-4部分中的每个部分可以产生一个样本。如果记录所在的任务为I/Q合路，那么就不会有Q路的信号，即没有6、8、10部分的样本，除了1-4部分、只有5、7、9部分的样本；如果记录所在的任务为I/Q分路，那么I路和Q路都有信号，1-10部分都对应了一个样本。\n",
    "\n",
    "如果一条记录是I/Q合路的，那么当其I路的帧同步锁（DPU_FRAMESYNCSTATUS1）锁上时，这条记录对应的1-4、5、7部分的样本为正常样本，反之这条记录就是一条异常记录，并构成一个在帧同步锁前就发生异常的异常样本；如果一条记录是I/Q分路的，那么只要当它的I路和Q路（DPU_FRAMESYNCSTATUS2）中的某一个帧同步锁锁上时，这条记录对应的1-4部分为正常样本，反之，这条记录为异常记录，并构成一个在帧同步锁前就发生异常的异常样本，更进一步，对于I路和Q路的中锁上的那一路而言，该路对应的样本在加上比特同步后的各个阶段的参数后依然是正常样本，对于I路和Q路中的没锁上的那一路而言，该路加上比特同步后的各个阶段的样本为异常样本。\n",
    "\n",
    "对每一部分都构造一个模型，并且用该部分的80%的正常样本去训练模型，用模型对剩下的20%的正常样本计算分数，找到正常样本所具有的最高分数，以该分数为阈值。在检测时，将异常样本的待检测部分的参数输入相应模型，如果模型输出的分数高于阈值，则证明该样本的该部分相对于上一部分增加的解调译码阶段发生异常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建parts文件夹，存放各部分的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strPartsDir = os.path.join(strDemodDir, \"parts\")\n",
    "        if os.path.exists(strPartsDir):\n",
    "            shutil.rmtree(strPartsDir)\n",
    "        os.mkdir(strPartsDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 帧同步锁前"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以帧同步锁为界限，把解调器的解调译码阶段分为两部分——帧同步锁前、帧同步锁后。\n",
    "\n",
    "建立空的sync文件夹，存放帧同步锁前的数据集\n",
    "\n",
    "执行后，文件结构如下：\n",
    "* 任务名/\n",
    "    * 解调器名/\n",
    "        * parts/\n",
    "            * sync/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strSyncDir = os.path.join(strDemodDir, \"parts/sync\")\n",
    "        if os.path.exists(strSyncDir):\n",
    "            shutil.rmtree(strSyncDir)\n",
    "        os.mkdir(strSyncDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中频控制\n",
    "可能的属性有： IFU_BWSELECTION（预设的带宽）、IFU_BWSELECTIONSTATUS（实际选择的带宽）、IFU_AGCCONSTANT（预设的agc时间常数）、IFU_AGCCONSTANTSTATUS（实际agc时间常数），IFU_FANSTATUS（风扇开关状态）、IFU_GAINMODESTATUS（增益控制）、IFU_GAIN1STATUS（增益状态）、IFU_GAIN2STATUS、IFU_GAIN3STATUS、IFU_INPUPORTTEMP（入口处温度）、IFU_OUTPUTPORTTEMP（出口处温度）、IFU_OUTPUTLEVELSET（预设输出电平）、IFU_INPUTLEVEL（输入电平）、IFU_OUTPUTLEVEL（输出电平）\n",
    "以下参数不是每个解调器都有：\n",
    "* 实际选择的带宽\n",
    "* 实际agc时间常数\n",
    "* 风扇开关\n",
    "* 增益控制\n",
    "* 增益状态\n",
    "\n",
    "综上所述，选用以下参数作为中频控制特征参数：\n",
    "* IFU_OUTPUTLEVELSET\n",
    "* IFU_INPUTLEVEL\n",
    "* IFU_OUTPUTLEVEL\n",
    "* IFU_INPUPORTTEMP\n",
    "* IFU_OUTPUTPORTTEMP\n",
    "\n",
    "1. 在sync下建立空的ifu文件夹\n",
    "2. 将输入对应的状态参数存入ifu\n",
    "3. 生成输入部分的样本，结果存入ifu/samples\n",
    "4. 对训练样本进行正则化，结果存入ifu/samples/normal/train/preprocessed\n",
    "\n",
    "正则化可将所有训练样本的属性值正则进入0-1之间。只能对训练集进行正则化，在测试的时候，应先用对训练集拟合好的正则化器正则化\n",
    "\n",
    "测试集的样本。\n",
    "执行完成后，具有如下目录结构：\n",
    "* 任务名/\n",
    "    * 解调器名/\n",
    "        * parts/\n",
    "            * sync/\n",
    "                * ifu/\n",
    "                    * samples/\n",
    "                        * normal/\n",
    "                            * train/\n",
    "                                * status.csv\n",
    "                                * preprocessed/\n",
    "                                    * status.csv\n",
    "                            * test/\n",
    "                                * status.csv\n",
    "                        * abnormal/\n",
    "                            * status.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "建立空的ifu文件夹，并将valid中的属于中频控制部分的状态参数存入status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存中频控制部分的特征参数名存入链表\n",
    "listNewFeatures = [\"IFU_OUTPUTLEVELSET\", \"IFU_INPUTLEVEL\", \"IFU_OUTPUTLEVEL\", \"IFU_INPUPORTTEMP\", \\\n",
    "                  \"IFU_OUTPUTPORTTEMP\"]\n",
    "listTotalFeatures = listNewFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空文件夹及载入数据\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    liststrDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in liststrDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/ifu\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "    \n",
    "        # 读入有效解调器设备状态参数\n",
    "        strValidStatusFile = os.path.join(strDemodDir, \"valid/status.csv\")\n",
    "        pdDfValidStatus = pd.read_csv(strValidStatusFile, index_col=\"RECTIME\")\n",
    "        pdDfSectionStatus = pdDfValidStatus[listNewFeatures]\n",
    "        strSectionStatusFile = os.path.join(strSectionDir, \"status.csv\")\n",
    "        pdDfSectionStatus.to_csv(strSectionStatusFile, index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成样本\n",
    "对于每个解调器，首先要从valid文件下的有效接收时间范围内的记录中读取帧同步锁锁上的记录。\n",
    "\n",
    "在从valid文件夹下读取的记录中，选出正常样本。这些对应于正常样本。将它们按照20%的比例随机划分成训练集和测试集。\n",
    "\n",
    "如果DEMOD_FRAMESYNCINPUT是2则任务为分路，如果为1则任务为合路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产生正常样本和异常样本记录indexes的函数。\n",
    "# 先检查DEMOD_FRAMESYNCINPUT的值，如果为合路，则只考虑DPU_FRAMESYNCSTATUS1是否为2；如果为分路，则两者有一个为2即可\n",
    "def fn_getNormalIndexesByFramelock(strDemodDir):\n",
    "    # 针对分路任务具有两个帧同步锁的情况\n",
    "    # 迭代标志数组的每个元素，如果有元素为true，则证明为正常记录\n",
    "    def fn_hasTrue(bnpNArr):\n",
    "        for b in bnpNArr:\n",
    "                if b:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "    pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "    if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "        # 合路\n",
    "        npNArrFilter = (pdDfValidStatus[\"DPU_FRAMESYNCSTATUS1\"] == 2).values\n",
    "        return npNArrFilter, ~npNArrFilter\n",
    "    else:\n",
    "        # 分路\n",
    "        npNArrFilter = (pdDfValidStatus.loc[:, [\"DPU_FRAMESYNCSTATUS1\", \"DPU_FRAMESYNCSTATUS2\"]] == 2).values\n",
    "        npNArrFilter = np.apply_along_axis(fn_hasTrue, 1, npNArrFilter)\n",
    "        return npNArrFilter, ~npNArrFilter\n",
    "# 按照百分比对正常样本划分训练集和测试集a\n",
    "def fn_splitTestAndTrain(pdDfTotalSamples, fPercent):\n",
    "    nSamples = pdDfTotalSamples.shape[0]\n",
    "    nTestSamples = int(nSamples * fPercent)\n",
    "    np.random.seed(42)\n",
    "    npNArrIndexes = np.random.permutation(nSamples)\n",
    "    return pdDfTotalSamples.iloc[npNArrIndexes[:nTestSamples], :], pdDfTotalSamples.iloc[npNArrIndexes[nTestSamples:], :]\n",
    "\n",
    "# 开始构造样本\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/ifu/samples\")\n",
    "        if os.path.exists(strSamplesDir):\n",
    "            shutil.rmtree(strSamplesDir)\n",
    "        os.mkdir(strSamplesDir)\n",
    "        \n",
    "        # 获取两路通道上帧同步锁有一个锁上的记录索引\n",
    "        npNArrNormalIndexes, npNArrAbnormalIndexes = fn_getNormalIndexesByFramelock(strDemodDir)\n",
    "        \n",
    "        # 读入中频控制部分的状态文件\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/ifu/status.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        # 构造异常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "        pdDfAbnormalTestingSamples = pdDfSectionStatus.loc[npNArrAbnormalIndexes, :]\n",
    "        pdDfAbnormalTestingSamples.to_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), index_label=\"RECTIME\")\n",
    "        \n",
    "        # 新建空的”normal“文件夹\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal\"))\n",
    "        # 划分训练集和测试集\n",
    "        pdDfNormalTotalSamples = pdDfSectionStatus.loc[npNArrNormalIndexes, :]\n",
    "        pdDfNormalTestingSamples, pdDfNormalTrainingSamples = fn_splitTestAndTrain(pdDfNormalTotalSamples, 0.20)\n",
    "        # 构造测试样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal/test\"))\n",
    "        pdDfNormalTestingSamples.to_csv(os.path.join(strSamplesDir, \"normal/test/samples.csv\"), index_label=\"RECTIME\")\n",
    "        \n",
    "        # 构造训练样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "        pdDfNormalTrainingSamples.to_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化\n",
    "用正则化器适应训练集，再用正则化器去正则化训练集和测试集。二元参数也可以通过正则化器正则。直接把整个输入部分的训练集正则化即可。将转化的结果存入preprocessed文件夹。该步执行完后，具有的文件夹结构如下：\n",
    "* ifu/\n",
    "    * samples/\n",
    "        * normal/\n",
    "            * train/\n",
    "                * samples.csv\n",
    "                * preprocessed/\n",
    "                    * samples.csv\n",
    "            * test/\n",
    "                * samples.csv\n",
    "                * preprocessed/\n",
    "                    * samples.csv\n",
    "        * abnormal/\n",
    "            * samples.csv\n",
    "            * preprocessed/\n",
    "                * samples.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建正则化器，并读入所有输入部分的训练样本用于正则化器的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读入所有中频控制部分的训练样本\n",
    "listTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfTrainingSamples = pd.read_csv(\\\n",
    "                              os.path.join(strDemodDir, \"parts/sync/ifu/samples/normal/train/samples.csv\"), \\\n",
    "                                          index_col=\"RECTIME\")\n",
    "        listTrainingSamples.append(pdDfTrainingSamples)\n",
    "pdDfTrainingSamples = pd.concat(listTrainingSamples)\n",
    "# 拟合\n",
    "# 正则化器\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(pdDfTrainingSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用拟合训练集的正则化器正则化训练集、正常测试集、异常测试集，存入preprocessed文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 中频控制部分的样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/ifu/samples\")\n",
    "\n",
    "        # 正则化训练集\n",
    "        strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "        # 清空预处理文件夹\n",
    "        if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTrainingSamples.empty:\n",
    "            pdDfNormalTrainingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfNormalTrainingSamples)\n",
    "        # 输出的时候忽略index，因为字符串类型的index在用dataset的时候没法解析\n",
    "        pdDfNormalTrainingSamples.to_csv(os.path.join(strPreprocessedNormalTrainingSamplesDir,\\\n",
    "                                                                  \"samples.csv\"), index=False)\n",
    "        \n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        strPreprocessedNormalTestingSamplesDir = os.path.join(strSamplesDir, \"normal/test/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTestingSamplesDir)\n",
    "        pdDfNormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTestingSamples.empty:\n",
    "            pdDfNormalTestingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfNormalTestingSamples)\n",
    "        pdDfNormalTestingSamples.to_csv(os.path.join(strPreprocessedNormalTestingSamplesDir, \"samples.csv\"), \\\n",
    "                                        index_label=\"RECTIME\")\n",
    "        \n",
    "        \n",
    "        # 正则化异常测试集\n",
    "        strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"),\\\n",
    "                                                 index_col=\"RECTIME\")\n",
    "        if not pdDfAbnormalTestingSamples.empty:\n",
    "            pdDfAbnormalTestingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfAbnormalTestingSamples)\n",
    "        pdDfAbnormalTestingSamples.to_csv(os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                          index_label=\"RECTIME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中频输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "中频输入特征参数：DEMOD_IFLEVEL（输入电平），DEMOD_EBNOVALUE（信噪比）。\\\n",
    "本来还想选用DEMOD_EBNOVALUEQCHL，但是这个参数在整个数据集中取值均为零，故忽略。\n",
    "\n",
    "建立空的input文件夹, 并将valid中的属于输入部分的状态参数存入status.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加中频输入部分参数名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把输入部分的属性存一下\n",
    "listNewFeatures = [\"DEMOD_IFLEVEL\", \"DEMOD_EBNOVALUE\"]\n",
    "# 更新总的属性列表。更新之前要检查是否已经更新过\n",
    "if [i for i in listNewFeatures if i in listTotalFeatures]:\n",
    "    pass\n",
    "else:\n",
    "    listTotalFeatures.extend(listNewFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    liststrDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in liststrDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/input\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "    \n",
    "        # 读入有效解调器设备状态参数\n",
    "        strValidStatusFile = os.path.join(strDemodDir, \"valid/status.csv\")\n",
    "        pdDfValidStatus = pd.read_csv(strValidStatusFile, index_col=\"RECTIME\")\n",
    "        pdDfSectionStatus = pdDfValidStatus[listNewFeatures]\n",
    "        pdDfSectionStatus.to_csv(os.path.join(strSectionDir, \"status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成样本\n",
    "需使用中频控制部分的训练集和测试集的index确定中频输入部分的训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 导入输入部分的数据，只包含输入部分的参数\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/input/status.csv\"),\\\n",
    "                                       index_col=\"RECTIME\")\n",
    "        \n",
    "        # 清空输入部分样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/input/samples\")        \n",
    "        if os.path.exists(strSamplesDir):\n",
    "            shutil.rmtree(strSamplesDir)\n",
    "        os.mkdir(strSamplesDir)\n",
    "        # 设置中频控制部分样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/ifu/samples\")\n",
    "        \n",
    "        # 正常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal\"))\n",
    "        # 正常训练样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "        # 读入中频控制部分正常训练样本的index\n",
    "        pdDfLastNormalTrainingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                             index_col=\"RECTIME\")\n",
    "        # 选取正常训练样本的index\n",
    "        pdDfNormalTrainingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTrainingSamples.index, :]\n",
    "        pdDfNormalTrainingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "        # 正常测试样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal/test\"))\n",
    "        # 读入中频控制部分的正常测试样本的index\n",
    "        pdDfLastNormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                                   index_col=\"RECTIME\")\n",
    "        # 选取正常测试样本\n",
    "        pdDfNormalTestingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTestingSamples.index, :]\n",
    "        pdDfNormalTestingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/test/samples.csv\"),\\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "        # 异常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "        # 读入中频控制部分异常测试样本的index\n",
    "        pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                     index_col=\"RECTIME\")\n",
    "        pdDfAbnormalTestingSamples = \\\n",
    "        pdDfSectionStatus.loc[pdDfLastAbnormalTestingSamples.index, :]\n",
    "        pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化\n",
    "用正则化器适应训练集，再用正则化器去正则化训练集和测试集。二元参数也可以通过正则化器正则。直接把整个输入部分的训练集正则化即可。将转化的结果存入preprocessed文件夹。该步执行完后，具有的文件夹结构如下：\n",
    "* input/\n",
    "    * samples/\n",
    "        * normal/\n",
    "            * train/\n",
    "                * samples.csv\n",
    "                * preprocessed/\n",
    "                    * samples.csv\n",
    "            * test/\n",
    "                * samples.csv\n",
    "                * preprocessed/\n",
    "                    * samples.csv\n",
    "        * abnormal/\n",
    "            * samples.csv\n",
    "            * preprocessed/\n",
    "                * samples.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建正则化器，并读入所有输入部分的训练样本用于正则化器的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读入所有中频控制部分的训练样本\n",
    "listTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfTrainingSamples = pd.read_csv(\\\n",
    "                              os.path.join(strDemodDir, \"parts/sync/input/samples/normal/train/samples.csv\"), \\\n",
    "                                          index_col=\"RECTIME\")\n",
    "        listTrainingSamples.append(pdDfTrainingSamples)\n",
    "pdDfTrainingSamples = pd.concat(listTrainingSamples)\n",
    "# 拟合\n",
    "# 正则化器\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(pdDfTrainingSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用拟合训练集的正则化器正则化训练集、正常测试集、异常测试集，将处理完成的数据集和中频控制部分相应的预处理后的样本集首尾连接。存入preprocessed文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 输入部分的样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/input/samples\")\n",
    "        # 中频控制部分的样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/ifu/samples\")\n",
    "        \n",
    "        # 正则化正常训练集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTrainingSamples.empty:\n",
    "            pdDfNormalTrainingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfNormalTrainingSamples)\n",
    "            # 因为预处理后的中频控制部分状态没有index，所以为了join，必须把这儿的index去掉\n",
    "            pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "        pdDfLastPreprocessedNormalTrainingSamples = pd.read_csv(\\\n",
    "                                      os.path.join(strLastSamplesDir, \"normal/train/preprocessed/samples.csv\"))\n",
    "        pdDfPreprocessedNormalTrainingSamples = pdDfLastPreprocessedNormalTrainingSamples.join(\\\n",
    "                                      pdDfNormalTrainingSamples)\n",
    "        pdDfPreprocessedNormalTrainingSamples.to_csv(\\\n",
    "                                      os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index=False)\n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTestingSamplesDir = os.path.join(strSamplesDir, \"normal/test/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTestingSamplesDir)\n",
    "        pdDfNormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTestingSamples.empty:\n",
    "            pdDfNormalTestingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfNormalTestingSamples)\n",
    "        pdDfLastPreprocessedNormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"normal/test/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedNormalTestingSamples = pdDfLastPreprocessedNormalTestingSamples.join(\\\n",
    "                                    pdDfNormalTestingSamples)\n",
    "        pdDfPreprocessedNormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedNormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")\n",
    "        \n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfAbnormalTestingSamples.empty:\n",
    "            pdDfAbnormalTestingSamples.loc[:, :] = oMinMaxScaler.transform(pdDfAbnormalTestingSamples)\n",
    "        pdDfLastPreprocessedAbnormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"abnormal/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedAbnormalTestingSamples = pdDfLastPreprocessedAbnormalTestingSamples.join(\\\n",
    "                                    pdDfAbnormalTestingSamples)\n",
    "        pdDfPreprocessedAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载波同步\n",
    "载波同步特征参数：DEMOD_CARRIEROFFSET（载波偏移）、DEMOD_CARRIERLOCK（载波锁）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "载入载波同步部分到carrier文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把载波同步部分的属性存一下\n",
    "listNewFeatures = [\"DEMOD_CARRIEROFFSET\", \"DEMOD_CARRIERLOCK\"]\n",
    "# 更新总的属性列表。更新之前要检查是否已经更新过\n",
    "if [i for i in listNewFeatures if i in listTotalFeatures]:\n",
    "    pass\n",
    "else:\n",
    "    listTotalFeatures.extend(listNewFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立空的文件夹carrier，将数据导入\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    liststrDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in liststrDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/carrier\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "    \n",
    "        # 读入有效解调器设备状态参数\n",
    "        strValidStatusFile = os.path.join(strDemodDir, \"valid/status.csv\")\n",
    "        pdDfValidStatus = pd.read_csv(strValidStatusFile, index_col=\"RECTIME\")\n",
    "        pdDfSectionStatus = pdDfValidStatus[listNewFeatures]\n",
    "        strSectionStatusFile = os.path.join(strSectionDir, \"status.csv\")\n",
    "        pdDfSectionStatus.to_csv(strSectionStatusFile, index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更改二元属性值\n",
    "DEMOD_CARRIERLOCK属性为锁上时为2，没锁上为1，在此将锁上改为用1表示：\n",
    "1. 将属性等于2的值改为1\n",
    "2. 将属性等于其它值的域改为0\n",
    "\n",
    "执行完成后文件结构如下：\n",
    "* sync/\n",
    "    * carrier/\n",
    "        * status.csv\n",
    "        * regularized/\n",
    "            * status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/carrier/status.csv\"), index_col=\"RECTIME\")\n",
    "        # 更改属性值\n",
    "        npIndexes = pdDfSectionStatus[\"DEMOD_CARRIERLOCK\"].values\n",
    "        npResult = np.zeros(npIndexes.size)\n",
    "        npResult[npIndexes == 2] = 1\n",
    "        pdDfSectionStatus[\"DEMOD_CARRIERLOCK\"] = npResult\n",
    "        \n",
    "        strRegularizedSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/regularized\")\n",
    "        if os.path.exists(strRegularizedSamplesDir):\n",
    "            shutil.rmtree(strRegularizedSamplesDir)\n",
    "        os.mkdir(strRegularizedSamplesDir)\n",
    "        pdDfSectionStatus.to_csv(os.path.join(strRegularizedSamplesDir, \"status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 导入载波同步部分的数据，只包含载波同步部分的参数。注意应该在regularized文件夹下导入\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/carrier/regularized/status.csv\"),\\\n",
    "                                       index_col=\"RECTIME\")\n",
    "        \n",
    "        # 清空载波同步部分样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/samples\")        \n",
    "        if os.path.exists(strSamplesDir):\n",
    "            shutil.rmtree(strSamplesDir)\n",
    "        os.mkdir(strSamplesDir)\n",
    "        # 设置输入部分样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/input/samples\")\n",
    "        \n",
    "        # 正常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal\"))\n",
    "        # 正常训练样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "        # 读入输入部分正常训练样本的index\n",
    "        pdDfLastNormalTrainingSamples = pd.read_csv(\\\n",
    "                             os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                             index_col=\"RECTIME\")\n",
    "        # 选取正常训练样本的index\n",
    "        pdDfNormalTrainingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTrainingSamples.index, :]\n",
    "        pdDfNormalTrainingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "        # 正常测试样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal/test\"))\n",
    "        # 读入输入部分的正常测试样本的index\n",
    "        pdDfLastNormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                                   index_col=\"RECTIME\")\n",
    "        # 选取正常测试样本\n",
    "        pdDfNormalTestingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTestingSamples.index, :]\n",
    "        pdDfNormalTestingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/test/samples.csv\"),\\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "        # 异常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "        # 读入输入部分异常测试样本的index\n",
    "        pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                     index_col=\"RECTIME\")\n",
    "        pdDfAbnormalTestingSamples = \\\n",
    "        pdDfSectionStatus.loc[pdDfLastAbnormalTestingSamples.index, :]\n",
    "        pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对载波同步部分的所有属性进行正则化，包括二元属性（二元属性正则化后不变）。存入preprocessed文件夹\n",
    "\n",
    "读入所有载波同步正常训练样本，利用正则化器适应正常训练样本。转化所有样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储需要正则化的参数名\n",
    "listNormFeatures = [\"DEMOD_CARRIEROFFSET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listNormalTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strDemodDir, \\\n",
    "                                            \"parts/sync/carrier/samples/normal/train/samples.csv\"),\\\n",
    "                                            index_col=\"RECTIME\")\n",
    "        listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormFeatures])\n",
    "pdDfNormalTrainingSamples = pd.concat(listNormalTrainingSamples)\n",
    "\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(pdDfNormalTrainingSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用正则化器转化所有样本，和输入部分对应的预处理过的样本组合后存入preprocessed文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 输入部分的样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/samples\")\n",
    "        # 中频控制部分的样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/input/samples\")\n",
    "        \n",
    "        # 正则化正常训练集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTrainingSamples.empty:\n",
    "            pdDfNormalTrainingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfNormalTrainingSamples[listNormFeatures])\n",
    "            # 因为预处理后的中频控制部分状态没有index，所以为了join，必须把这儿的index去掉\n",
    "            pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "        pdDfLastPreprocessedNormalTrainingSamples = pd.read_csv(\\\n",
    "                                      os.path.join(strLastSamplesDir, \"normal/train/preprocessed/samples.csv\"))\n",
    "        pdDfPreprocessedNormalTrainingSamples = pdDfLastPreprocessedNormalTrainingSamples.join(\\\n",
    "                                      pdDfNormalTrainingSamples)\n",
    "        pdDfPreprocessedNormalTrainingSamples.to_csv(\\\n",
    "                                      os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index=False)\n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTestingSamplesDir = os.path.join(strSamplesDir, \"normal/test/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTestingSamplesDir)\n",
    "        pdDfNormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTestingSamples.empty:\n",
    "            pdDfNormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfNormalTestingSamples[listNormFeatures])\n",
    "        pdDfLastPreprocessedNormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"normal/test/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedNormalTestingSamples = pdDfLastPreprocessedNormalTestingSamples.join(\\\n",
    "                                    pdDfNormalTestingSamples)\n",
    "        pdDfPreprocessedNormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedNormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")\n",
    "        \n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfAbnormalTestingSamples.empty:\n",
    "            pdDfAbnormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfAbnormalTestingSamples[listNormFeatures])\n",
    "        pdDfLastPreprocessedAbnormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"abnormal/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedAbnormalTestingSamples = pdDfLastPreprocessedAbnormalTestingSamples.join(\\\n",
    "                                    pdDfAbnormalTestingSamples)\n",
    "        pdDfPreprocessedAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比特同步\n",
    "比特同步的特征参数：DEMOD_BITRATE（比特率）、DEMOD_BITRATEOFFSET（比特偏移）、DEMOD_BITRATEOFFSET（比特偏移Q通道）、DEMOD_BITLOCK（比特锁）、DEMOD_BITLOCKQCHL（比特锁Q通道）、DEMOD_TOTALBITNUMBER（总比特数）、DEMOD_TOTALBITNUMBERQCHL（总比特数Q通道）\n",
    "\n",
    "本来对于比特数这个参数，需要用当前秒的比特数减去上一秒的比特数，来得到当前秒接收的比特数。但是减完之后发现，有一些上报秒被的比特数被减成了零。感觉这个参数存在问题，故舍弃。\n",
    "\n",
    "比特率是一个预设值。比特锁属性0为锁上，1为没锁。所以要把它们regularize一下。总比特数是一个累加值，要注意做差分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入数据\n",
    "存储比特同步增加的属性，更新总的属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "listNewFeatures = [\"DEMOD_BITRATE\", \"DEMOD_BITRATEOFFSET\", \"DEMOD_BITRATEOFFSETQCHL\",\\\n",
    "                   \"DEMOD_BITLOCK\", \"DEMOD_BITLOCKQCHL\"]\n",
    "# 更新总的属性列表。更新之前要检查是否已经更新过\n",
    "if [i for i in listNewFeatures if i in listTotalFeatures]:\n",
    "    pass\n",
    "else:\n",
    "    listTotalFeatures.extend(listNewFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入比特部分的数据入bit文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strBitDir = os.path.join(strDemodDir, \"parts/sync/bit\")\n",
    "        if os.path.exists(strBitDir):\n",
    "            shutil.rmtree(strBitDir)\n",
    "        os.mkdir(strBitDir)\n",
    "        \n",
    "        strValidStatusFile = os.path.join(strDemodDir, \"valid/status.csv\")\n",
    "        pdDfValidStatus = pd.read_csv(strValidStatusFile, index_col=\"RECTIME\")\n",
    "        pdDfBitStatus = pdDfValidStatus[listNewFeatures]\n",
    "        pdDfBitStatus.to_csv(os.path.join(strBitDir, \"status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更改二元属性的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比特锁属性0为锁上，1为没锁。要把比特锁属性值为0改为1，其它改为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/bit\")        \n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strSectionDir, \"status.csv\"), index_col=\"RECTIME\")\n",
    "        # 更改bitlock和bitlcokqchl的值\n",
    "        npIndexes = pdDfSectionStatus[\"DEMOD_BITLOCK\"].values\n",
    "        npResult = np.zeros(npIndexes.size)\n",
    "        npResult[npIndexes == 0] = 1\n",
    "        pdDfSectionStatus[\"DEMOD_BITLOCK\"] = npResult\n",
    "        npIndexes = pdDfSectionStatus[\"DEMOD_BITLOCKQCHL\"].values\n",
    "        npResult = np.zeros(npIndexes.size)\n",
    "        npResult[npIndexes == 0] = 1\n",
    "        pdDfSectionStatus[\"DEMOD_BITLOCKQCHL\"] = npResult\n",
    "        \n",
    "        strRegularizedStatusDir = os.path.join(strSectionDir, \"regularized\")\n",
    "        if os.path.exists(strRegularizedStatusDir):\n",
    "            shutil.rmtree(strRegularizedStatusDir)\n",
    "        os.mkdir(strRegularizedStatusDir)\n",
    "        pdDfSectionStatus.to_csv(os.path.join(strRegularizedStatusDir, \"status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 导入比特同步部分的数据。注意应该在regularized文件夹下导入\n",
    "        pdDfSectionStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/bit/regularized/status.csv\"),\\\n",
    "                                       index_col=\"RECTIME\")\n",
    "        \n",
    "        # 清空比特同步部分样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/bit/samples\")        \n",
    "        if os.path.exists(strSamplesDir):\n",
    "            shutil.rmtree(strSamplesDir)\n",
    "        os.mkdir(strSamplesDir)\n",
    "        # 设置载波同步样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/samples\")\n",
    "        \n",
    "        # 正常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal\"))\n",
    "        # 正常训练样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "        # 读入输入部分正常训练样本的index\n",
    "        pdDfLastNormalTrainingSamples = pd.read_csv(\\\n",
    "                             os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                             index_col=\"RECTIME\")\n",
    "        # 选取正常训练样本的index\n",
    "        pdDfNormalTrainingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTrainingSamples.index, :]\n",
    "        pdDfNormalTrainingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "        # 正常测试样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"normal/test\"))\n",
    "        # 读入输入部分的正常测试样本的index\n",
    "        pdDfLastNormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                                   index_col=\"RECTIME\")\n",
    "        # 选取正常测试样本\n",
    "        pdDfNormalTestingSamples = \\\n",
    "            pdDfSectionStatus.loc[pdDfLastNormalTestingSamples.index, :]\n",
    "        pdDfNormalTestingSamples.to_csv(\\\n",
    "                               os.path.join(strSamplesDir, \"normal/test/samples.csv\"),\\\n",
    "                               index_label=\"RECTIME\")\n",
    "        \n",
    "        # 异常样本\n",
    "        os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "        # 读入输入部分异常测试样本的index\n",
    "        pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                     index_col=\"RECTIME\")\n",
    "        pdDfAbnormalTestingSamples = \\\n",
    "        pdDfSectionStatus.loc[pdDfLastAbnormalTestingSamples.index, :]\n",
    "        pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二元变量要单独处理。因为如果训练集里所有的某二元变量的值均为1，那么，当用这个训练集训练过后的scaler去转化其它数据集的时候，其他数据集的1变量会被全部转化为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储需要正则化的参数名\n",
    "listNormFeatures = [\"DEMOD_BITRATE\", \"DEMOD_BITRATEOFFSET\", \"DEMOD_BITRATEOFFSETQCHL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listNormalTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strDemodDir, \\\n",
    "                                            \"parts/sync/bit/samples/normal/train/samples.csv\"),\\\n",
    "                                            index_col=\"RECTIME\")\n",
    "        listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormFeatures])\n",
    "        \n",
    "pdDfNormalTrainingSamples = pd.concat(listNormalTrainingSamples)\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(pdDfNormalTrainingSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 比特同步部分的样本文件夹\n",
    "        strSamplesDir = os.path.join(strDemodDir, \"parts/sync/bit/samples\")\n",
    "        # 载波同步部分的样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/carrier/samples\")\n",
    "        \n",
    "        # 正则化正常训练集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "        pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTrainingSamples.empty:\n",
    "            pdDfNormalTrainingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfNormalTrainingSamples[listNormFeatures])\n",
    "            # 因为预处理后的中频控制部分状态没有index，所以为了join，必须把这儿的index去掉\n",
    "            pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "        pdDfLastPreprocessedNormalTrainingSamples = pd.read_csv(\\\n",
    "                                      os.path.join(strLastSamplesDir, \"normal/train/preprocessed/samples.csv\"))\n",
    "        pdDfPreprocessedNormalTrainingSamples = pdDfLastPreprocessedNormalTrainingSamples.join(\\\n",
    "                                      pdDfNormalTrainingSamples)\n",
    "        pdDfPreprocessedNormalTrainingSamples.to_csv(\\\n",
    "                                      os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index=False)\n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedNormalTestingSamplesDir = os.path.join(strSamplesDir, \"normal/test/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedNormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedNormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedNormalTestingSamplesDir)\n",
    "        pdDfNormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfNormalTestingSamples.empty:\n",
    "            pdDfNormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfNormalTestingSamples[listNormFeatures])\n",
    "        pdDfLastPreprocessedNormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"normal/test/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedNormalTestingSamples = pdDfLastPreprocessedNormalTestingSamples.join(\\\n",
    "                                    pdDfNormalTestingSamples)\n",
    "        pdDfPreprocessedNormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedNormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")\n",
    "        \n",
    "        \n",
    "        # 正则化正常测试集\n",
    "        # 清空预处理文件夹\n",
    "        strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "        if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "            shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "        pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        if not pdDfAbnormalTestingSamples.empty:\n",
    "            pdDfAbnormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "                oMinMaxScaler.transform(pdDfAbnormalTestingSamples[listNormFeatures])\n",
    "        pdDfLastPreprocessedAbnormalTestingSamples = pd.read_csv(\\\n",
    "                                 os.path.join(strLastSamplesDir, \"abnormal/preprocessed/samples.csv\"),\\\n",
    "                                 index_col=\"RECTIME\")\n",
    "        pdDfPreprocessedAbnormalTestingSamples = pdDfLastPreprocessedAbnormalTestingSamples.join(\\\n",
    "                                    pdDfAbnormalTestingSamples)\n",
    "        pdDfPreprocessedAbnormalTestingSamples.to_csv(\\\n",
    "                                    os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                    index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 维特比译码\n",
    "如果任务为I/Q合路，那么从维特比译码之后都只使用了I路；如果任务为I/Q分路，那么从维特比译码之后使用了两路。\n",
    "\n",
    "载入数据时，要先检查控制文件中的DEMOD_FRAMESYNCINPUT参数.如果I/Q合路，则在vi文件夹下只用建立I文件夹，表示只使用了I路；反之，新建I和Q文件夹。\n",
    "\n",
    "DEMOD_FRAMESYNCINPUT参数有0、1、2三个值，其中已知1代表合路、2代表分路、不知道0代表什么。\n",
    "\n",
    "合路和分路的处理方式具有以下不同：\n",
    "\n",
    "合路只用了I路，所以可以直接依照比特同步阶段的样本index去生成样本；但分路用了两路，每个分路具有自己的帧同步锁，而在分路之前的样本是否为正样本的判断方式是：只要有一个分路的帧同步锁锁上，所以即使分路之前的样本为正常样本，也不能就此判断其对应的两个分路均为正常样本。\n",
    "\n",
    "由于在分路的情况下，正常样本和异常样本可能存在变动，所以记录在分路之前需要进行的预处理也需要重新进行。在载入数据的时候也需要把比特同步部分的属性载进来。\n",
    "\n",
    "维特比译码部分包含参数：DEMOD_VITERBIINPUT（维特比输入开关）、DEMOD_VITERBI1DECODER、DEMOD_VITERBI2DECODER、DEMOD_VITERBI1TOTALBITNUMBER（总比特数）、DEMOD_VITERBI2TOTALBITNUMBER、DEMOD_VITERBI1ERRORBITNUMBER（误比特数）、DEMOD_VITERBI2ERRORBITNUMBER.\\\n",
    "DEMOD_VITERBIINPUT值为2表示维特比打开，所以需要先正规化。\n",
    "跟比特数有关的变量是累加值，所以应该先减去前一秒的值得到这一秒内的包数。但有以下特殊情况：\n",
    "* 有效接收时间的第一秒的比特数是相对于无效接收时间的最后一秒而言的，所以应该先读入无效的最后一秒的比特数\n",
    "* 如果某一秒的包数比前一秒少，那就不用减了\n",
    "\n",
    "在I/Q合路的情况下，维特比译码的样本可以依照比特同步的样本生成。分路情况下，要对于比特同步中的正常样本检查I路和Q路的帧同步锁，把没锁的样本放到异常样本中去。\n",
    "\n",
    "把算完包数的状态参数文件存入diff文件夹，执行完成后具有如下文件结构：\n",
    "* parts/\n",
    "    * sync/\n",
    "        * vi/\n",
    "            * I/\n",
    "                * regularized/\n",
    "                    * status.csv\n",
    "                * diff/\n",
    "                    * status.csv\n",
    "                * status.csv\n",
    "            * Q/（合路时没有这个文件夹）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据\n",
    "清空vi文件夹和其下的I、Q文件夹。读入维特比部分的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 还没有分路之前全部属性，按照顺序存储在链表中。分路之后的全部属性分为两个链表\n",
    "# 把维特比部分的属性存一下。需要把两个通道分别存储\n",
    "listNewIFeatures = [\"DEMOD_VITERBIINPUT\", \"DEMOD_VITERBI1DECODER\",\\\n",
    "            \"DEMOD_VITERBI1TOTALBITNUMBER\", \"DEMOD_VITERBI1ERRORBITNUMBER\"]\n",
    "listTotalIFeatures = listTotalFeatures + listNewIFeatures\n",
    "listNewQFeatures = [\"DEMOD_VITERBIINPUT\", \"DEMOD_VITERBI2DECODER\",\\\n",
    "            \"DEMOD_VITERBI2TOTALBITNUMBER\", \"DEMOD_VITERBI2ERRORBITNUMBER\"]\n",
    "listTotalQFeatures = listTotalFeatures + listNewQFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 读入控制文件，为了判断合路还是分路\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/vi\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "        \n",
    "        pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路，要包括前面的所有属性，因为在正则化的时候，是所有的分路一起正则化，不论是合路还是分路它们的I路和Q路都是\n",
    "            # 同等的关系\n",
    "            os.mkdir(os.path.join(strSectionDir, \"I\"))\n",
    "            pdDfIStatus = pdDfValidStatus[listTotalIFeatures]\n",
    "            pdDfIStatus.to_csv(os.path.join(strSectionDir, \"I/status.csv\"), index_label=\"RECTIME\")\n",
    "        else:\n",
    "            # 分路。要读I路和Q路两路数据。并且要把包括前面的所有的属性都读进来\n",
    "            os.mkdir(os.path.join(strSectionDir, \"I\"))\n",
    "            pdDfIStatus = pdDfValidStatus[listTotalIFeatures]\n",
    "            pdDfIStatus.to_csv(os.path.join(strSectionDir, \"I/status.csv\"), index_label=\"RECTIME\")\n",
    "            os.mkdir(os.path.join(strSectionDir, \"Q\"))\n",
    "            pdDfQStatus = pdDfValidStatus[listTotalQFeatures]\n",
    "            pdDfQStatus.to_csv(os.path.join(strSectionDir, \"Q/status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更改二元属性的值\n",
    "更改DEMOD_VITERBIINPUT的属性，存入regularied。2为维特比有效，其余为无效。\n",
    "* vi/\n",
    "    * I（Q）/\n",
    "        * status.csv\n",
    "        * regularized/\n",
    "            * status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变所有需要改变值的二元属性，由于目前在分路上没有二元属性，所以它们的二元属性都是公共的\n",
    "# 比特同步及之前的部分的二元属性只有在分路的情况下才用改变，因为只有分路的情况才包含前面的所有属性\n",
    "def fn_regularizeIOrQ(strIOrQ):\n",
    "    strRegularizedStatusDir = os.path.join(strSectionDir, strIOrQ + \"/regularized\")\n",
    "    if os.path.exists(strRegularizedStatusDir):\n",
    "        shutil.rmtree(strRegularizedStatusDir)\n",
    "    os.mkdir(strRegularizedStatusDir)\n",
    "    pdDfStatus = pd.read_csv(os.path.join(strSectionDir, strIOrQ + \"/status.csv\"), index_col=\"RECTIME\")\n",
    "    # DEMOD_CARRIERLOCK\n",
    "    npIndexes = pdDfStatus[\"DEMOD_CARRIERLOCK\"].values\n",
    "    npResult = np.zeros(npIndexes.size)\n",
    "    npResult[npIndexes == 2] = 1\n",
    "    pdDfStatus[\"DEMOD_CARRIERLOCK\"] = npResult\n",
    "    # 更改bitlock和bitlcokqchl的值\n",
    "    npIndexes = pdDfStatus[\"DEMOD_BITLOCK\"].values\n",
    "    npResult = np.zeros(npIndexes.size)\n",
    "    npResult[npIndexes == 0] = 1\n",
    "    pdDfStatus[\"DEMOD_BITLOCK\"] = npResult\n",
    "    npIndexes = pdDfStatus[\"DEMOD_BITLOCKQCHL\"].values\n",
    "    npResult = np.zeros(npIndexes.size)\n",
    "    npResult[npIndexes == 0] = 1\n",
    "    pdDfStatus[\"DEMOD_BITLOCKQCHL\"] = npResult\n",
    "    # DEMOD_VITERBIINPUT\n",
    "    npIndexes = pdDfStatus[\"DEMOD_VITERBIINPUT\"].values\n",
    "    npResult = np.zeros(npIndexes.size)\n",
    "    npResult[npIndexes == 2] = 1\n",
    "    pdDfStatus[\"DEMOD_VITERBIINPUT\"] = npResult\n",
    "    pdDfStatus.to_csv(os.path.join(strRegularizedStatusDir, \"status.csv\"), index_label=\"RECTIME\")\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/vi\")   \n",
    "\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路, 直接规整I路\n",
    "            fn_regularizeIOrQ(\"I\")\n",
    "        else:\n",
    "            # 分路，规整I路和Q路的到目前为止所有的需要规整的二元属性\n",
    "            # I路\n",
    "            fn_regularizeIOrQ(\"I\")\n",
    "            # Q路\n",
    "            fn_regularizeIOrQ(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算每秒的比特数\n",
    "先读入raw文件夹下的状态参数。找到第一个有效上报点的前一个点的参数。如果第一个有效上报点的参数大于前一点的参数则做差，反之直接保留。其余上报点的参数直接为该秒的值与前一秒值之差。计算后把状态de文件存入diff文件夹。如果有的秒数在做完差后的值为零，直接令它的值等于前一秒的比特数\n",
    "* I(Q)/\n",
    "    * status.csv\n",
    "    * diff/\n",
    "        * status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存入比特数的属性名\n",
    "listAggreIFeatures = [\"DEMOD_VITERBI1TOTALBITNUMBER\", \"DEMOD_VITERBI1ERRORBITNUMBER\"]\n",
    "listAggreQFeatures = [\"DEMOD_VITERBI2TOTALBITNUMBER\", \"DEMOD_VITERBI2ERRORBITNUMBER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只在维特比译码阶段出现了累积量\n",
    "def fn_subNumber(nWin):\n",
    "        if nWin.size == 1:\n",
    "            return  nWin[0]\n",
    "        elif nWin[1] < nWin[0]:\n",
    "                return nWin[1]\n",
    "        else:\n",
    "                return nWin[1] - nWin[0]\n",
    "\n",
    "# 把0元素全部改为它的上一个元素的值\n",
    "def fn_fillZeros(nWin):\n",
    "    if nWin.size == 1:\n",
    "        return nWin[0]\n",
    "    elif nWin[1] == 0:\n",
    "        return nWin[0]\n",
    "    else:\n",
    "        return nWin[1]\n",
    "\n",
    "# 对状态函数做差。输入状态的通道文件夹，和需要做差的属性，完成做差，存入diff\n",
    "def fn_subIOrQ(strDir, listAggreFeatures):\n",
    "    # 清空diff\n",
    "    strDiffDir = os.path.join(strDir, \"diff\")\n",
    "    if os.path.exists(strDiffDir):\n",
    "        shutil.rmtree(strDiffDir)\n",
    "    os.mkdir(strDiffDir)\n",
    "    pdDfStatus = pd.read_csv(os.path.join(strDir, \"regularized/status.csv\"), index_col=\"RECTIME\")\n",
    "    # 从第二个有效上报时间点开始，算每个点单独的包数\n",
    "    pdDfStatus[listAggreFeatures] = pdDfStatus[listAggreFeatures].rolling(window=2, min_periods=1).\\\n",
    "    apply(fn_subNumber, raw=True)\n",
    "    # 找到第一个有效时间点之前的时间点的整数坐标\n",
    "    strFirstValidIndex = pdDfStatus.index[0]\n",
    "    i = 0\n",
    "    for strIndex in pdDfRawStatus.index:\n",
    "        if strIndex == strFirstValidIndex:\n",
    "            # 取出第一个有效时间点之前的记录和第一个有效时间点记录\n",
    "            pdSeriesRaw = pdDfRawStatus.loc[pdDfRawStatus.index[i - 1], listAggreFeatures]\n",
    "            pdSeriesToBeCulled = pdDfStatus.loc[strFirstValidIndex, listAggreFeatures]\n",
    "            for j in range(len(pdSeriesToBeCulled)):\n",
    "                # 如果第一个有效点记录的在某域上的值大于等于相应的第一个有效时间点之前的记录的值，则做差\n",
    "                pdSeriesToBeCulled[j] = pdSeriesToBeCulled[j] - pdSeriesRaw[j] \\\n",
    "                    if pdSeriesToBeCulled[j] >= pdSeriesRaw[j] else pdSeriesToBeCulled[j]\n",
    "            pdDfStatus.loc[strFirstValidIndex, listAggreFeatures] = pdSeriesToBeCulled\n",
    "        i += 1\n",
    "    # 填充0值\n",
    "    pdDfStatus[listAggreFeatures] = pdDfStatus[listAggreFeatures].rolling(window=2, min_periods=1).\\\n",
    "    apply(fn_fillZeros, raw=True)\n",
    "    pdDfStatus.to_csv(os.path.join(strDiffDir, \"status.csv\"), index_label=\"RECTIME\")\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 读入原始状态参数\n",
    "        pdDfRawStatus = pd.read_csv(os.path.join(strDemodDir, \"raw/status.csv\"), index_col=\"RECTIME\")\n",
    "        # 读入控制参数文件\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        # 因为需要做差的目前只在维特比译码这儿有，所以可以无论如何先做I路，再做选择性的Q路\n",
    "        # 无论如何先做I路\n",
    "        fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/vi/I\"), listAggreIFeatures)\n",
    "        \n",
    "        # 如果分路则做Q路\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 分路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/vi/I\"), listAggreIFeatures)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/vi/I\"), listAggreIFeatures)\n",
    "            # Q路\n",
    "            fn_subCh(os.path.join(strDemodDir, \"parts/sync/vi/Q\"), listAggreQFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在读入比特同步的相应样本后，需要根据不同的分路，检查不同的帧同步锁。把前一次的正常训练样本和正常测试样本中在该分路上没有锁上的\n",
    "# 记录归为该分路上的异常样本\n",
    "# 为了逻辑简便，即使合路不存在这种需要根据分路的帧同步锁再次判断该分路的样本是否为异常样本的情况，还是对合路情况进行如上操作\n",
    "def fn_genIOrQSamples(strIOrQ):\n",
    "    # 清空I和Q路的样本文件夹\n",
    "    strSamplesDir = os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/samples\")\n",
    "    if os.path.exists(strSamplesDir):\n",
    "        shutil.rmtree(strSamplesDir)\n",
    "    os.mkdir(strSamplesDir)\n",
    "\n",
    "    # 导入维特比部分做差后的数据\n",
    "    pdDfStatus = pd.read_csv(\\\n",
    "             os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/diff/status.csv\"), index_col=\"RECTIME\")\n",
    "\n",
    "\n",
    "    # 新建normal和abnormal样本文件夹\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal\"))\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "\n",
    "    # 存储由正常训练样本和正常测试样本转变为异常样本的index的链表\n",
    "    listNewAbnormalIndexes = []\n",
    "    # 找到正常训练样本和正常测试样本中转变为异常测试样本的index，并存入链表\n",
    "    # I路对应DPU_FRAMESYNCSTATUS1；Q路对应DPU_FRAMESYNCSTATUS2\n",
    "    for strIndex in pdDfLastNormalTrainingSamples.index: \n",
    "        if not pdDfValidStatus.loc[strIndex, \"DPU_FRAMESYNCSTATUS\" + (\"1\" if strIOrQ == \"I\" else \"2\")] == 2:\n",
    "            # 没锁上，把index存入链表\n",
    "            listNewAbnormalIndexes.append(strIndex)\n",
    "    for strIndex in pdDfLastNormalTestingSamples.index:\n",
    "        if not pdDfValidStatus.loc[strIndex, \"DPU_FRAMESYNCSTATUS\" + (\"1\" if strIOrQ == \"I\" else \"2\")] == 2:\n",
    "            # 没锁上，把index存入链表\n",
    "            listNewAbnormalIndexes.append(strIndex)\n",
    "    # 利用比特同步的正常训练样本的index除去listNewAbnormalIndexes中索引后的index产生正常训练样本\n",
    "    pdDfNormalTrainingSamples = \\\n",
    "        pdDfStatus.loc[[strIndex for strIndex in pdDfLastNormalTrainingSamples.index \\\n",
    "                             if strIndex not in listNewAbnormalIndexes], :]\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "    pdDfNormalTrainingSamples.to_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"), index_label=\"RECTIME\")\n",
    "    # 正常测试样本\n",
    "    pdDfNormalTestingSamples = \\\n",
    "        pdDfStatus.loc[[strIndex for strIndex in pdDfLastNormalTestingSamples.index \\\n",
    "                            if strIndex not in listNewAbnormalIndexes], :]\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal/test\"))\n",
    "    pdDfNormalTestingSamples.to_csv(os.path.join(strSamplesDir,\"normal/test/samples.csv\"), index_label=\"RECTIME\")\n",
    "    # 异常测试样本\n",
    "    pdDfAbnormalTestingSamples = \\\n",
    "        pdDfStatus.loc[list(pdDfLastAbnormalTestingSamples.index) + listNewAbnormalIndexes, :]\n",
    "    pdDfAbnormalTestingSamples.to_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), index_label=\"RECTIME\")\n",
    "    \n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 读入控制文件，为了判断合路还是分路\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        # 设置比特同步样本文件夹\n",
    "        strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/bit/samples\")\n",
    "        # 读入比特同步的正常训练样本\n",
    "        pdDfLastNormalTrainingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        # 读入比特同步的正常测试样本\n",
    "        pdDfLastNormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/test/samples.csv\"),\\\n",
    "                                                  index_col=\"RECTIME\")\n",
    "        # 读入比特同步的异常测试样本\n",
    "        pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"),\n",
    "                                                    index_col=\"RECTIME\")\n",
    "        \n",
    "        # 读入解调器的有效状态参数，因为要利用它的帧同步锁\n",
    "        pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            fn_genIOrQSamples(\"I\")\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_genIOrQSamples(\"I\")\n",
    "            # Q路\n",
    "            fn_genIOrQSamples(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储分路之前的I/Q共有的需要正则化的属性名\n",
    "listNormIQFeatures = [\"IFU_OUTPUTLEVELSET\", \"IFU_INPUTLEVEL\", \"IFU_OUTPUTLEVEL\", \"IFU_INPUPORTTEMP\", \"IFU_OUTPUTPORTTEMP\",\\\n",
    "                    \"DEMOD_IFLEVEL\", \"DEMOD_EBNOVALUE\",\\\n",
    "                    \"DEMOD_CARRIEROFFSET\",\\\n",
    "                    \"DEMOD_BITRATE\", \"DEMOD_BITRATEOFFSET\", \"DEMOD_BITRATEOFFSETQCHL\"]\n",
    "listNormIFeatures = listNormIQFeatures + [\"DEMOD_VITERBI1TOTALBITNUMBER\", \"DEMOD_VITERBI1ERRORBITNUMBER\"]\n",
    "listNormQFeatures = listNormIQFeatures + [\"DEMOD_VITERBI2TOTALBITNUMBER\", \"DEMOD_VITERBI2ERRORBITNUMBER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listNormalTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        # 设置维特比译码的文件夹\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/vi\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路，把I路的需要正则化的数据转化成np数组后存入链表\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "                os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormIFeatures].values)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "            os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormIFeatures].values)\n",
    "            # Q路\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "            os.path.join(strSectionDir, \"Q/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples[listNormQFeatures].values)\n",
    "\n",
    "npNArrNormalTrainingSamples = np.concatenate(listNormalTrainingSamples)\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(npNArrNormalTrainingSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用正则化器正则化样本的需要正则化的属性，存入preprocessed文件夹。\n",
    "def fn_normalizeIOrQSamples(strIOrQ, listNormFeatures):\n",
    "    # 维特比译码的样本文件夹\n",
    "    strSamplesDir = os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/samples\")\n",
    "\n",
    "    # 正则化正常训练集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "    os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "    pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                                     index_col=\"RECTIME\")\n",
    "    if not pdDfNormalTrainingSamples.empty:\n",
    "        pdDfNormalTrainingSamples.loc[:, listNormFeatures] = \\\n",
    "            oMinMaxScaler.transform(pdDfNormalTrainingSamples.loc[:, listNormFeatures])\n",
    "        pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "    pdDfNormalTrainingSamples.to_csv(\\\n",
    "                                 os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                    index=False)\n",
    "\n",
    "    # 正则化正常测试集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedNormalTestingSamplesDir = os.path.join(strSamplesDir, \"normal/test/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedNormalTestingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedNormalTestingSamplesDir)\n",
    "    os.mkdir(strPreprocessedNormalTestingSamplesDir)\n",
    "    pdDfNormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                      index_col=\"RECTIME\")\n",
    "    if not pdDfNormalTestingSamples.empty:\n",
    "        pdDfNormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "            oMinMaxScaler.transform(pdDfNormalTestingSamples.loc[:, listNormFeatures])\n",
    "    pdDfNormalTestingSamples.to_csv(\\\n",
    "                               os.path.join(strPreprocessedNormalTestingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index_label=\"RECTIME\")\n",
    "\n",
    "    # 正则化异常测试集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "    os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "    pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                      index_col=\"RECTIME\")\n",
    "    if not pdDfAbnormalTestingSamples.empty:\n",
    "        pdDfAbnormalTestingSamples.loc[:, listNormFeatures] = \\\n",
    "            oMinMaxScaler.transform(pdDfAbnormalTestingSamples.loc[:, listNormFeatures])\n",
    "    pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                               os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"), \\\n",
    "                                       index_label=\"RECTIME\")\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            fn_normalizeIOrQSamples(\"I\", listNormIFeatures)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_normalizeIOrQSamples(\"I\", listNormIFeatures)\n",
    "            # Q路\n",
    "            fn_normalizeIOrQSamples(\"Q\", listNormQFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 帧同步\n",
    "帧同步部分包含属性：DPU_FRAMELEN1（帧长）、DPU_FRAMEHEADLEN1（帧头长度）、DPU_RECEIVEDFRAMECOUNTER1（收帧计数）、DPU_DROPOUTFRAMECOUNTER1（丢帧计数）、DPU_TOTALBITNUMBER1（帧头总比特数）、DPU_ERRORBITNUMBER1（帧头误比特数）。其中DPU_FRAMELEN1、DPU_FRAMEHEADLEN1是预设值。其余皆为累加值，需要做差。这些属性均可正则化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据\n",
    "在parts/sync下新建frame文件夹。将数据存入frame中。该步结束后，文件结构如下：\n",
    "* parts/\n",
    "    * sync/\n",
    "        * frame/\n",
    "            * I(Q)/\n",
    "                * status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把帧同步部分的属性存一下。需要把两个通道分别存储\n",
    "listNewIFeatures = [\"DPU_FRAMELEN1\", \"DPU_FRAMEHEADLEN1\", \"DPU_RECEIVEDFRAMECOUNTER1\", \\\n",
    "                     \"DPU_DROPOUTFRAMECOUNTER1\", \"DPU_TOTALBITNUMBER1\", \"DPU_ERRORBITNUMBER1\"]\n",
    "listNewQFeatures = [\"DPU_FRAMELEN2\", \"DPU_FRAMEHEADLEN2\", \"DPU_RECEIVEDFRAMECOUNTER2\", \\\n",
    "                     \"DPU_DROPOUTFRAMECOUNTER2\", \"DPU_TOTALBITNUMBER2\", \"DPU_ERRORBITNUMBER2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/frame\")\n",
    "        if os.path.exists(strSectionDir):\n",
    "            shutil.rmtree(strSectionDir)\n",
    "        os.mkdir(strSectionDir)\n",
    "        \n",
    "        # 只把帧同步部分新增的属性存入文件夹，因为后面产生样本和正则化的时候可以依照维特比译码\n",
    "        os.mkdir(os.path.join(strSectionDir, \"I\"))\n",
    "        pdDfValidStatus = pd.read_csv(os.path.join(strDemodDir, \"valid/status.csv\"), index_col=\"RECTIME\")\n",
    "        pdDfStatus = pdDfValidStatus[listNewIFeatures]\n",
    "        pdDfStatus.to_csv(os.path.join(strSectionDir, \"I/status.csv\"), index_label=\"RECTIME\")\n",
    "        \n",
    "        os.mkdir(os.path.join(strSectionDir, \"Q\"))\n",
    "        pdDfStatus = pdDfValidStatus[listNewQFeatures]\n",
    "        pdDfStatus.to_csv(os.path.join(strSectionDir, \"Q/status.csv\"), index_label=\"RECTIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算每秒的比特数和帧数\n",
    "该步完成后，文件结构如下：\n",
    "* frame/\n",
    "    * I(Q)/\n",
    "        * status.csv\n",
    "        * diff/\n",
    "            * status.csv\n",
    "            \n",
    "发现DPU_DROPOUTFRAMECOUNTER1似乎不是一个累积量，因为再很多任务里面，它的值一直不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存入比特数和帧数的属性名\n",
    "listAggreIFeatures = [\"DPU_RECEIVEDFRAMECOUNTER1\", \\\n",
    "                     \"DPU_TOTALBITNUMBER1\", \"DPU_ERRORBITNUMBER1\"]\n",
    "listAggreQFeatures = [\"DPU_RECEIVEDFRAMECOUNTER2\", \\\n",
    "                     \"DPU_TOTALBITNUMBER2\", \"DPU_ERRORBITNUMBER2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只在维特比译码阶段出现了累积量\n",
    "def fn_subNumber(nWin):\n",
    "        if nWin.size == 1:\n",
    "            return  nWin[0]\n",
    "        elif nWin[1] < nWin[0]:\n",
    "                return nWin[1]\n",
    "        else:\n",
    "                return nWin[1] - nWin[0]\n",
    "\n",
    "# 把0元素全部改为它的上一个元素的值\n",
    "def fn_fillZeros(nWin):\n",
    "    if nWin.size == 1:\n",
    "        return nWin[0]\n",
    "    elif nWin[1] == 0:\n",
    "        return nWin[0]\n",
    "    else:\n",
    "        return nWin[1]\n",
    "\n",
    "# 对状态函数做差。输入状态的通道文件夹，和需要做差的属性，完成做差，存入diff\n",
    "def fn_subIOrQ(strDir, listAggreFeatures):\n",
    "    # 清空diff\n",
    "    strDiffDir = os.path.join(strDir, \"diff\")\n",
    "    if os.path.exists(strDiffDir):\n",
    "        shutil.rmtree(strDiffDir)\n",
    "    os.mkdir(strDiffDir)\n",
    "    pdDfStatus = pd.read_csv(os.path.join(strDir, \"status.csv\"), index_col=\"RECTIME\")\n",
    "    # 从第二个有效上报时间点开始，算每个点单独的包数\n",
    "    pdDfStatus[listAggreFeatures] = pdDfStatus[listAggreFeatures].rolling(window=2, min_periods=1).\\\n",
    "    apply(fn_subNumber, raw=True)\n",
    "    # 找到第一个有效时间点之前的时间点的整数坐标\n",
    "    strFirstValidIndex = pdDfStatus.index[0]\n",
    "    i = 0\n",
    "    for strIndex in pdDfRawStatus.index:\n",
    "        if strIndex == strFirstValidIndex:\n",
    "            # 取出第一个有效时间点之前的记录和第一个有效时间点记录\n",
    "            pdSeriesRaw = pdDfRawStatus.loc[pdDfRawStatus.index[i - 1], listAggreFeatures]\n",
    "            pdSeriesToBeCulled = pdDfStatus.loc[strFirstValidIndex, listAggreFeatures]\n",
    "            for j in range(len(pdSeriesToBeCulled)):\n",
    "                # 如果第一个有效点记录的在某域上的值大于等于相应的第一个有效时间点之前的记录的值，则做差\n",
    "                pdSeriesToBeCulled[j] = pdSeriesToBeCulled[j] - pdSeriesRaw[j] \\\n",
    "                    if pdSeriesToBeCulled[j] >= pdSeriesRaw[j] else pdSeriesToBeCulled[j]\n",
    "            pdDfStatus.loc[strFirstValidIndex, listAggreFeatures] = pdSeriesToBeCulled\n",
    "        i += 1\n",
    "    # 填充0值\n",
    "    pdDfStatus[listAggreFeatures] = pdDfStatus[listAggreFeatures].rolling(window=2, min_periods=1).\\\n",
    "    apply(fn_fillZeros, raw=True)\n",
    "    pdDfStatus.to_csv(os.path.join(strDiffDir, \"status.csv\"), index_label=\"RECTIME\")\n",
    "\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        # 读入原始状态参数\n",
    "        pdDfRawStatus = pd.read_csv(os.path.join(strDemodDir, \"raw/status.csv\"), index_col=\"RECTIME\")\n",
    "        # 读入控制参数文件\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        # 如果分路则做Q路\n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 分路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/frame/I\"), listAggreIFeatures)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/frame/I\"), listAggreIFeatures)\n",
    "            # Q路\n",
    "            fn_subIOrQ(os.path.join(strDemodDir, \"parts/sync/frame/Q\"), listAggreQFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依照维特比同步生成样本\n",
    "def fn_genIOrQSamples(strIOrQ):\n",
    "    # 导入帧同步部分的数据。注意应该在diff文件夹下导入\n",
    "    pdDfStatus = pd.read_csv(os.path.join(strDemodDir, \"parts/sync/frame/\" + strIOrQ + \"/diff/status.csv\"),\\\n",
    "                                   index_col=\"RECTIME\")\n",
    "\n",
    "    # 清空帧同步部分样本文件夹\n",
    "    strSamplesDir = os.path.join(strDemodDir, \"parts/sync/frame/\" + strIOrQ + \"/samples\")        \n",
    "    if os.path.exists(strSamplesDir):\n",
    "        shutil.rmtree(strSamplesDir)\n",
    "    os.mkdir(strSamplesDir)\n",
    "    # 设置维特比译码样本文件夹\n",
    "    strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/samples\")\n",
    "\n",
    "    # 正常样本\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal\"))\n",
    "    # 正常训练样本\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal/train\"))\n",
    "    # 读入输入部分正常训练样本的index\n",
    "    pdDfLastNormalTrainingSamples = pd.read_csv(\\\n",
    "                         os.path.join(strLastSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                         index_col=\"RECTIME\")\n",
    "    # 选取正常训练样本的index\n",
    "    pdDfNormalTrainingSamples = \\\n",
    "        pdDfStatus.loc[pdDfLastNormalTrainingSamples.index, :]\n",
    "    pdDfNormalTrainingSamples.to_csv(\\\n",
    "                           os.path.join(strSamplesDir, \"normal/train/samples.csv\"), \\\n",
    "                           index_label=\"RECTIME\")\n",
    "\n",
    "    # 正常测试样本\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"normal/test\"))\n",
    "    # 读入输入部分的正常测试样本的index\n",
    "    pdDfLastNormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                               index_col=\"RECTIME\")\n",
    "    # 选取正常测试样本\n",
    "    pdDfNormalTestingSamples = \\\n",
    "        pdDfStatus.loc[pdDfLastNormalTestingSamples.index, :]\n",
    "    pdDfNormalTestingSamples.to_csv(\\\n",
    "                           os.path.join(strSamplesDir, \"normal/test/samples.csv\"),\\\n",
    "                           index_label=\"RECTIME\")\n",
    "\n",
    "    # 异常样本\n",
    "    os.mkdir(os.path.join(strSamplesDir, \"abnormal\"))\n",
    "    # 读入输入部分异常测试样本的index\n",
    "    pdDfLastAbnormalTestingSamples = pd.read_csv(os.path.join(strLastSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                 index_col=\"RECTIME\")\n",
    "    pdDfAbnormalTestingSamples = \\\n",
    "    pdDfStatus.loc[pdDfLastAbnormalTestingSamples.index, :]\n",
    "    pdDfAbnormalTestingSamples.to_csv(\\\n",
    "                                os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                index_label=\"RECTIME\")\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    strJobDir = os.path.join(strJobsDir, strJob)\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(strJobDir)\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            fn_genIOrQSamples(\"I\")\n",
    "        else:\n",
    "            # 分路\n",
    "            fn_genIOrQSamples(\"I\")\n",
    "            fn_genIOrQSamples(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化\n",
    "帧同步新增的所有属性都需要正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listNormalTrainingSamples = []\n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        # 设置维特比译码的文件夹\n",
    "        strSectionDir = os.path.join(strDemodDir, \"parts/sync/frame\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路，把I路的需要正则化的数据转化成np数组后存入链表\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "                os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples.values)\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "            os.path.join(strSectionDir, \"I/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples.values)\n",
    "            # Q路\n",
    "            pdDfNormalTrainingSamples = pd.read_csv(\\\n",
    "            os.path.join(strSectionDir, \"Q/samples/normal/train/samples.csv\"), index_col=\"RECTIME\")\n",
    "            listNormalTrainingSamples.append(pdDfNormalTrainingSamples.values)\n",
    "\n",
    "npNArrNormalTrainingSamples = np.concatenate(listNormalTrainingSamples)\n",
    "oMinMaxScaler = sklearn.preprocessing.MinMaxScaler()\n",
    "oMinMaxScaler.fit(npNArrNormalTrainingSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用正则化器正则化样本的需要正则化的属性，和维特比译码的正则化结果组合后，存入preprocessed文件夹。\n",
    "def fn_normalizeIOrQSamples(strIOrQ):\n",
    "    # 帧同步的样本文件夹\n",
    "    strSamplesDir = os.path.join(strDemodDir, \"parts/sync/frame/\" + strIOrQ + \"/samples\")\n",
    "    # 维特比译码的样本文件夹\n",
    "    strLastSamplesDir = os.path.join(strDemodDir, \"parts/sync/vi/\" + strIOrQ + \"/samples\")\n",
    "\n",
    "    # 正则化正常训练集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedNormalTrainingSamplesDir = os.path.join(strSamplesDir, \"normal/train/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedNormalTrainingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedNormalTrainingSamplesDir)\n",
    "    os.mkdir(strPreprocessedNormalTrainingSamplesDir)\n",
    "    pdDfNormalTrainingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/train/samples.csv\"),\\\n",
    "                                                index_col=\"RECTIME\")\n",
    "    if not pdDfNormalTrainingSamples.empty:\n",
    "        pdDfNormalTrainingSamples.loc[:, :] = \\\n",
    "            oMinMaxScaler.transform(pdDfNormalTrainingSamples)\n",
    "        # 因为预处理后的中频控制部分状态没有index，所以为了join，必须把这儿的index去掉\n",
    "        pdDfNormalTrainingSamples.reset_index(drop=True, inplace=True)\n",
    "    pdDfLastPreprocessedNormalTrainingSamples = pd.read_csv(\\\n",
    "                                  os.path.join(strLastSamplesDir, \"normal/train/preprocessed/samples.csv\"))\n",
    "    pdDfPreprocessedNormalTrainingSamples = pdDfLastPreprocessedNormalTrainingSamples.join(\\\n",
    "                                  pdDfNormalTrainingSamples)\n",
    "    pdDfPreprocessedNormalTrainingSamples.to_csv(\\\n",
    "                                  os.path.join(strPreprocessedNormalTrainingSamplesDir, \"samples.csv\"), \\\n",
    "                                   index=False)\n",
    "\n",
    "    # 正则化正常测试集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedNormalTestingSamplesDir = os.path.join(strSamplesDir, \"normal/test/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedNormalTestingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedNormalTestingSamplesDir)\n",
    "    os.mkdir(strPreprocessedNormalTestingSamplesDir)\n",
    "    pdDfNormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"normal/test/samples.csv\"), \\\n",
    "                                                index_col=\"RECTIME\")\n",
    "    if not pdDfNormalTestingSamples.empty:\n",
    "        pdDfNormalTestingSamples.loc[:, :] = \\\n",
    "            oMinMaxScaler.transform(pdDfNormalTestingSamples)\n",
    "    pdDfLastPreprocessedNormalTestingSamples = pd.read_csv(\\\n",
    "                             os.path.join(strLastSamplesDir, \"normal/test/preprocessed/samples.csv\"),\\\n",
    "                             index_col=\"RECTIME\")\n",
    "    pdDfPreprocessedNormalTestingSamples = pdDfLastPreprocessedNormalTestingSamples.join(\\\n",
    "                                pdDfNormalTestingSamples)\n",
    "    pdDfPreprocessedNormalTestingSamples.to_csv(\\\n",
    "                                os.path.join(strPreprocessedNormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                index_label=\"RECTIME\")\n",
    "\n",
    "\n",
    "    # 正则化正常测试集\n",
    "    # 清空预处理文件夹\n",
    "    strPreprocessedAbnormalTestingSamplesDir = os.path.join(strSamplesDir, \"abnormal/preprocessed\")\n",
    "    if os.path.exists(strPreprocessedAbnormalTestingSamplesDir):\n",
    "        shutil.rmtree(strPreprocessedAbnormalTestingSamplesDir)\n",
    "    os.mkdir(strPreprocessedAbnormalTestingSamplesDir)\n",
    "    pdDfAbnormalTestingSamples = pd.read_csv(os.path.join(strSamplesDir, \"abnormal/samples.csv\"), \\\n",
    "                                                index_col=\"RECTIME\")\n",
    "    if not pdDfAbnormalTestingSamples.empty:\n",
    "        pdDfAbnormalTestingSamples.loc[:, :] = \\\n",
    "            oMinMaxScaler.transform(pdDfAbnormalTestingSamples)\n",
    "    pdDfLastPreprocessedAbnormalTestingSamples = pd.read_csv(\\\n",
    "                             os.path.join(strLastSamplesDir, \"abnormal/preprocessed/samples.csv\"),\\\n",
    "                             index_col=\"RECTIME\")\n",
    "    pdDfPreprocessedAbnormalTestingSamples = pdDfLastPreprocessedAbnormalTestingSamples.join(\\\n",
    "                                pdDfAbnormalTestingSamples)\n",
    "    pdDfPreprocessedAbnormalTestingSamples.to_csv(\\\n",
    "                                os.path.join(strPreprocessedAbnormalTestingSamplesDir, \"samples.csv\"),\\\n",
    "                                index_label=\"RECTIME\")\n",
    "    \n",
    "for strJob in os.listdir(strJobsDir):\n",
    "    listDemodDirs = fn_getDemodDirsOfAJob(os.path.join(strJobsDir, strJob))\n",
    "    for strDemodDir in listDemodDirs:\n",
    "        pdDfControl = pd.read_csv(os.path.join(strDemodDir, \"control.csv\"), index_col=\"RECTIME\")\n",
    "        \n",
    "        if pdDfControl[\"DEMOD_FRAMESYNCINPUT\"][0] == 1:\n",
    "            # 合路\n",
    "            fn_normalizeIOrQSamples(\"I\")\n",
    "        else:\n",
    "            # 分路\n",
    "            # I路\n",
    "            fn_normalizeIOrQSamples(\"I\")\n",
    "            # Q路\n",
    "            fn_normalizeIOrQSamples(\"Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 译码部分\n",
    "DPU_DECODEPOS为0则解扰在译码前、1则解扰在译码后。由于crc只能起到校验的作用，所以不管crc，只考虑ldpc和rs。ldpc和rs两者不会同时存在。目前打算用聚类的方法，将译码部分的记录分成正常和异常两部分，可能样本含量多的cluster代表正常样本、反之为异常样本。\n",
    "\n",
    "DPU_SYNCTHRESHOLD2、DPU_CTLTHRESHOLD2、DPU_LTSTHRESHOLD2、DPU_BITSLIPWINDOW2这四个参数是在帧同步时需要设定的参数，但是在整个数据集里它们的值均为3。所以目前暂时不考虑它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据\n",
    "在parts下新建decode文件夹。译码也是分为两个通道进行的，所以要在decode下新建ch1和ch2文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
